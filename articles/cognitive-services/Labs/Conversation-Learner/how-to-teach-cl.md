---
title: Conversation Learner で学習させる方法 - Microsoft Cognitive Services | Microsoft Docs
titleSuffix: Azure
description: Conversation Learner で学習させる方法について説明します。
services: cognitive-services
author: v-jaswel
manager: nolachar
ms.service: cognitive-services
ms.component: conversation-learner
ms.topic: article
ms.date: 04/30/2018
ms.author: v-jaswel
ms.openlocfilehash: 41fe350fd712f6c521a9020af9a540e554abe94b
ms.sourcegitcommit: 4e5ac8a7fc5c17af68372f4597573210867d05df
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 07/20/2018
ms.locfileid: "39170601"
---
# <a name="how-to-teach-with-conversation-learner"></a>Conversation Learner で学習させる方法 

このドキュメントでは、Conversation Learner がどのようなシグナルを認識し、また、どのように学習するのかについて説明します。  

学習させる作業は、はっきり異なる 2 つのステップに分解することができます。エンティティ抽出とアクション選択です。

## <a name="entity-extraction"></a>エンティティ抽出

Conversation Learner でのエンティティ抽出には、内部的に [LUIS](https://www.luis.ai) が使用されています。  LUIS に慣れている方であれば、その経験は Conversation Learner でのエンティティ抽出にも通用します。

エンティティ抽出モデルは、ユーザー発話に含まれる "*コンテンツ*" と "*コンテキスト*" を認識します。  たとえば、"What's the weather in Seattle" といった発話の中で既に "Seattle" という単語が都市としてラベル付けされていれば、エンティティ抽出は、別の発話 ("Population of Seattle" など) でも、同じコンテンツ ("Seattle") を都市として認識することができます。発話が大きく異なっていてもかまいません。  逆に、"Schedule a meeting with Francis" の "Francis" が人名として認識されていれば、"Set up a meeting with Robin" など、似たコンテキストの中で、それまで遭遇したことのない新しい名前を認識することができます。  機械学習は、コンテンツ、コンテキスト、またはその両方の聞き取りのタイミングを、トレーニングの例に基づいて推論するのです。

エンティティ抽出によって認識されるのは、現時点では最新の発話のコンテンツだけです。  アクション選択 (後述) とは異なり、会話の履歴、たとえば前のシステム ターンや前のユーザー ターン、前に認識されたエンティティは認識されません。  その結果、エンティティ抽出の動作はすべての発話で横断的に "共有" されることになります。  たとえば、ユーザーの発話 "I want Apple" に含まれる "Apple" が、あるユーザー発話の中で "Fruit" というエンティティ型としてラベル付けされている場合、エンティティ抽出モデルは、この発話 ("I want Apple") に出現する "Apple" が常に "Fruit" としてラベル付けされているものと考えます。

エンティティ抽出で期待した動作が得られない場合は、次のような対策を講じることができます。

- 最初に試すことは、トレーニングの例を増やすことです。特に、エンティティの代表的なコンテキスト (周囲の単語) や例外が明らかになるような例を追加してみてください。
- 必要に応じて "予期されるエンティティ" プロパティをアクションに追加することを検討してください。  詳細については、予期されるエンティティに関するチュートリアルを参照してください。
- エンティティを抽出する処理コードを `EntityExtractionCallback` に手動で追加することもできますが、これは次善の手法といえます。システムの完成度が高まっていく過程で機械学習の向上から恩恵を受けることができないためです。

## <a name="action-selection"></a>アクション選択

アクション選択には、再帰型ニューラル ネットワークが使用されています。再帰型ニューラル ネットワークは、すべての会話履歴を入力として受け取ります。  したがってアクション選択は、先行するユーザー発話、エンティティ値、システム発話を認識するステートフルなプロセスです。  

一部のシグナルは、学習プロセスによって必然的に優先されます。  つまり Conversation Learner がアクション選択の判断を "より優先度の高い" シグナルを使って説明できる場合、そのシグナルが使われます。一方、説明できない場合には、"より優先度の低い" シグナルが使用されます。

以下の表は、Conversation Learner におけるすべてのシグナルと、アクション選択によって使用されるシグナルを示したものです。  ユーザー発話における語順は無視されることに注意してください。

シグナル | 優先度 (1=最も高い) | メモ
--- | --- | --- 
先行ターンにおけるシステム アクション | 1 | 
現在のターンにエンティティが存在する | 1 | 
最初のターンであるかどうか | 1 |
完全に一致する単語が現在のユーザー発話内に存在する | 2 | 
同様の意味を持つ単語が現在のユーザー発話に存在する | 3 | 
先行ターンより前のシステム アクション | 4 |
現在のターンより前のターンにエンティティが存在する | 4 | 
現在のターンより前のユーザー発話 | 5 | 

> [!NOTE]
> アクション選択では、システム アクションの内容 (テキスト、カード コンテンツ、API の名前または動作) ではなく、システム アクションの ID だけが取得されます。  そのため、アクションの内容を変更しても、アクション選択モデルの振る舞いは変化しません。
>
> さらに、エンティティの内容/値ではなく、それらの存在/不在だけが使用されます。

アクション選択で期待した動作が得られない場合は、次のような対策を講じることができます。

- トレーニング会話 (特に、アクション選択で注目すべきシグナルの例示となるような会話) を追加します。  たとえば、アクション選択で他のシグナルよりも優先すべきシグナルがある場合、その優先されるシグナルが同じ状態で、かつその他のシグナルが変化する状態にあるような例を与えます。  一部のシーケンスは、ある程度のトレーニング会話を与えて学習させることができます。
- アクションの定義に "Required (必須)" エンティティと "Disqualifying (不適格)" エンティティを追加します。  これによって、どのようなときにアクションを選択できるかという点に制限が加えられるため、ビジネス ルールや常識的パターンを効果的に表現することができます。 

## <a name="updates-to-models"></a>モデルに対する更新

エンティティ、アクション、トレーニング会話を UI から追加したり編集したりすると、そのたびに、エンティティ抽出モデルとアクション選択モデルの両方を再トレーニングする要求が生成されます。  この要求はキューに格納され、再トレーニングは非同期的に実行されます。  新しいモデルが利用できる状態になると、それ以降、そのモデルがエンティティ抽出とアクション選択に使用されます。  この再トレーニング プロセスの所要時間は通常 5 秒ほどですが、モデルが複雑な場合やトレーニング サービスに対する負荷が高い場合には、それよりも長くかかることがあります。

トレーニングは非同期的に実行されるため、行った編集がすぐに反映されるとは限りません。  変更を加えてから 5 秒から 10 秒経っても、エンティティ抽出またはアクション選択で期待した動作が得られない場合、このことが原因として考えられます。

## <a name="next-steps"></a>次の手順

> [!div class="nextstepaction"]
> [既定値と境界](./cl-values-and-boundaries.md)
