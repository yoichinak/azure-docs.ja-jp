---
title: Speech Service を使用して言語モデルを作成する方法 - Microsoft Cognitive Services
description: Microsoft Cognitive Services の Speech Service を使用して言語モデルを作成する方法について説明します。
services: cognitive-services
author: PanosPeriorellis
ms.service: cognitive-services
ms.component: speech-service
ms.topic: tutorial
ms.date: 06/25/2018
ms.author: panosper
ms.openlocfilehash: 0161a691cbec45a87ade218d1707a2784d7f1cfc
ms.sourcegitcommit: 068fc623c1bb7fb767919c4882280cad8bc33e3a
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 07/27/2018
ms.locfileid: "39283886"
---
# <a name="tutorial-create-a-custom-language-model"></a>チュートリアル: カスタム言語モデルを作成する

このドキュメントでは、カスタム言語モデルを作成します。これは、Microsoft が提供する既存の最先端の音声モデルと組み合わせて使用することで、アプリケーションに音声操作を追加できます。

このドキュメントでは、以下の方法を説明します。
> [!div class="checklist"]
> * データを準備する
> * 言語データ セットをインポートする
> * カスタム言語モデルを作成する

Cognitive Services アカウントをお持ちでない場合は、開始する前に [無料アカウント](https://azure.microsoft.com/try/cognitive-services/) を作成してください。

## <a name="prerequisites"></a>前提条件

[[Cognitive Services サブスクリプション]](https://customspeech.ai/Subscriptions) ページを開いて、Cognitive Services アカウントに接続されることを確認します。

**[Connect existing subscription]\(既存のサブスクリプションに接続する\)** ボタンをクリックすると、Azure portal で作成された Speech Service サブスクリプションに接続できます。

Azure portal での Speech Service サブスクリプションの作成については、[概要](get-started.md)ページを参照してください。

## <a name="prepare-the-data"></a>データを準備する

アプリケーション用のカスタム言語モデルを作成するには、以下のような発言用例の一覧をシステムに提供する必要があります。

*   "患者は先週じんましんが出ました。"
*   "患者には、完治したヘルニア手術の傷跡があります。"

文は、完全な文章である必要も、文法的に正しい文章である必要もありませんが、デプロイ中にシステムで予想される発言を正確に反映している必要があります。 これらの用例は、ユーザーがアプリケーションを使用して実行するタスクのスタイルとコンテンツの両方を反映する必要があります。

言語モデルのデータは、UTF-8 BOM で記述する必要があります。 テキスト ファイルには、1 行につき 1 つの用例 (文、発言、またはクエリ) を含める必要があります。

特定の用語の重み (重要度) を高くする場合は、その用語を含む発話をデータに数回追加できます。 

言語データの主な要件を次の表にまとめます。

| プロパティ | 値 |
|----------|-------|
| テキストのエンコード | UTF-8 BOM|
| 1 行あたりの発言の数 | 1 |
| ファイルの最大サイズ | 1.5 GB |
| 解説 | 文字を 5 回以上繰り返さないようにします (例: 'aaaaa')|
| 解説 | '\t' や [Unicode 文字コード表](http://www.utf8-chartable.de/) の U+00A1 より上の UTF-8 文字は使用しません|
| 解説 | 一意に発音する方法がないため、URI も拒否されます|

テキストのインポート時に、システムで処理できるように、テキストの正規化が行われます。 ただし、"_データをアップロードする前_" にユーザーが行う必要があるいくつかの重要な正規化があります。 言語データを準備する際に、適切な言語を決定するには、[文字起こしガイドライン](prepare-transcription.md)を参照してください。

## <a name="language-support"></a>言語のサポート

次の言語は、カスタムの **Speech to Text** 言語モデルでサポートされています。

サポートされている言語の一覧を表示するには、[こちら](supported-languages.md)をクリックしてください

## <a name="import-the-language-data-set"></a>言語データ セットをインポートする

[Language Datasets]\(言語データセット\) 行の [インポート] ボタンをクリックすると、サイトでは、新しいデータ セットをアップロードするためのページが表示されます。

言語データ セットをインポートする準備ができたら、[Speech Service Portal](https://customspeech.ai) にログインします。  次に、上部のリボンの [Custom Speech] ドロップダウン メニューをクリックし、[Adaptation Data]\(適応データ\) を選択します。 初めて Speech Service にデータをアップロードしようとすると、"データセット" という名前の空のテーブルが表示されます。

新しいデータ セットをアップロードするには、[言語データ セット] 行の [インポート] ボタンをクリックします。新しいデータ セットをアップロードするためのサイトのページが表示されます。 今後そのデータ セットを識別できるように名前と説明を入力し、ロケールを選択します。 次に、[ファイルの選択] ボタンを使用して、言語データのテキスト ファイルを探します。 その後、[インポート] をクリックしてデータ セットをアップロードします。 データ セットのサイズによっては、インポートに数分かかる場合があります。

![試す](media/stt/speech-language-datasets-import.png)

インポートが完了したら、言語データ テーブルに戻り、言語データ セットに対応するエントリがあることを確認します。 一意の ID (GUID) が割り当てられることに注意してください。 データには、現在の状態を反映するステータスもあります。 そのステータスは、処理を待っている間は [待機中] に、検証中は [処理中] に、使用する準備ができると [完了] になります。 データの検証では、ファイル内のテキストに対する一連のチェックと、データのテキストの正規化が行われます。

ステータスが [完了] のときに、[レポートの表示] をクリックして、言語データ検証レポートを表示できます。 失敗した発言の詳細と共に、検証に成功した発言の数と失敗した発言の数が表示されます。 次の例では、不適切な文字が原因で 2 つの用例が検証に失敗しています (このデータ セットでは、1 行目に 2 つのタブ文字が使用され、2 行目に ASCII 印刷可能文字セット以外の文字が複数使用されているのに対し、3 行目は空白になっていました)。

![試す](media/stt/speech-language-datasets-report.png)

言語データ セットは、ステータスが [完了] のときに、それを使用してカスタム言語モデルを作成できます。

![試す](media/stt/speech-language-datasets.png)

## <a name="create-a-custom-language-model"></a>カスタム言語モデルを作成する

言語データが準備できたら、[メニュー] ドロップダウン メニューから [言語モデル] をクリックして、カスタム言語モデルの作成プロセスを開始します。 このページには、現在のカスタム言語モデルを持つ [言語モデル] という名前のテーブルが含まれています。 カスタム言語モデルをまだ作成していない場合、テーブルは空になります。 現在のロケールは、テーブル内で関連するデータ エントリの横に表示されます。

アクションを実行する前に、適切なロケールを選択する必要があります。 現在のロケールは、データ、モデル、デプロイのページすべてでテーブル タイトルに示されます。 ロケールを変更するには、テーブルのタイトルの下にある [Change Locale]\(ロケールの変更\) をクリックすると、ロケールの確認ページが表示されます。 テーブルに戻るには [OK] をクリックします。

[言語モデルの作成] ページで、このモデルの関連情報 (使用されるデータ セットなど) を追跡するために役立つ [名前] と [説明] を入力します。 次に、ドロップダウン メニューから [Base Language Model]\(ベース言語モデル\) を選択します。 このモデルがカスタマイズの開始点となります。 2 つのベース言語モデルから選択できます。 Search and Dictation モデルは、コマンド、検索クエリ、ディクテーションなどのアプリケーションに向けて発せられる音声に適しています。 Conversational モデルは、会話形式での発話の認識に適しています。 この種類の音声は、通常は他の人に向けて発せられるものであり、コール センターや会議で発生します。 "Universal" という新しいモデルも一般公開されています。 Universal は、すべてのシナリオに対処し、最終的に Search and Dictation モデルや Conversational モデルに代わることを目的としています。

5.  以下の例では、ベース言語モデルを指定した後、[Language Data]\(言語データ\) ドロップダウン メニューを使用してカスタマイズに使用する言語データ セットを選択します。

![試す](media/stt/speech-language-models-create2.png)

音響モデルの作成と同じように、処理が完了したら、必要に応じて、新しいモデルのオフライン テストを実行することを選択できます。 モデルの評価には、音響データ セットが必要です。

言語モデルのオフライン テストを実行するには、[オフライン テスト] の横にあるチェック ボックスを選択します。 次に、ドロップダウン メニューから音響モデルを選択します。 カスタム音響モデルを作成していない場合は、Microsoft ベースの音響モデルがメニューの唯一のモデルになります。 Conversational LM ベース モデルを選択した場合は、ここで Conversational AM を使用する必要があります。 Search and Dictation LM モデルを使用する場合は、Search and Dictate AM を選択する必要があります。

最後に、評価を実行するために使用する音響データ セットを選択します。

処理を開始する準備ができたら、[作成] をクリックすると、言語モデルのテーブルが表示されます。 このモデルに対応するテーブルに新しいエントリがあります。 ステータスは、モデルの状態を反映し、[待機中]、[処理中]、[完了] を含むさまざまな状態を通過します。

モデルが [完了] 状態に達したら、エンドポイントに展開できます。 [結果の表示] をクリックすると、オフライン テストの結果が表示されます (実行した場合)。

ある時点でモデルの [名前] または [説明] を変更する場合は、言語モデル テーブルの適切な行の [編集] リンクを使用できます。

## <a name="next-steps"></a>次の手順

- [Speech 試用版サブスクリプションを取得する](https://azure.microsoft.com/try/cognitive-services/)
- [C# で音声を認識する方法](quickstart-csharp-dotnet-windows.md)
- [Git サンプル データ](https://github.com/Microsoft/Cognitive-Custom-Speech-Service)
