---
title: Custom Voice とは - Azure Cognitive Services
description: この記事では、Microsoft Text to Speech での音声のカスタマイズの概要を説明します。この機能を使うと、認識可能な独自のブランド音声を作成できます。
services: cognitive-services
author: noellelacharite
ms.service: cognitive-services
ms.topic: article
ms.date: 05/07/2018
ms.author: nolach
ms.openlocfilehash: 84493ae83515c0458bf5b9e9cf44603300a8b4f7
ms.sourcegitcommit: 068fc623c1bb7fb767919c4882280cad8bc33e3a
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 07/27/2018
ms.locfileid: "39284889"
---
# <a name="creating-custom-voice-fonts"></a>カスタム音声フォントの作成

Microsoft Text to Speech (TTS) の音声カスタマイズ機能を使うと、"*音声フォント*" つまり認識可能な独自のブランドの音声を作成できます。 

音声フォントを作成するには、スタジオで録音し、関連するスクリプトをトレーニング データとしてアップロードします。 サービスは、録音に合わせて調整された一意の音声モデルを作成します。 その後、この音声フォントを使って音声を合成できます。 

概念実証のために少量のデータで始めることができます。 ただし、データが多いほど、より自然で本格的な音声になります。

音声のカスタマイズは、米国英語 (en-US) と本土中国語 (zh-CN) で使用できます。

## <a name="prerequisites"></a>前提条件

現在、Text to Speech 音声カスタマイズ機能はプライベート プレビューです。 アクセスするには[申請フォームに入力してください](https://forms.office.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR0N8Vcdi8MZBllkZb70o6KdURjRaUzhBVkhUNklCUEMxU0tQMEFPMjVHVi4u)。

Azure アカウントと音声サービスへのサブスクリプションも必要です。 まだない場合は、[作成](https://docs.microsoft.com/azure/cognitive-services/speech-service/get-started)してください。 次のように、サブスクリプションを Custom Voice ポータルに接続します。

1. アクセスの申請に使用したのと同じ Microsoft アカウントを使って、[Custom Voice ポータル](https://customvoice.ai)にログオンします。

2. 右上のアカウント名の下にある [Subscriptions]\(サブスクリプション\) に移動します。

    ![サブスクリプション](media/custom-voice/subscriptions.png)

3. [Subscriptions]\(サブスクリプション\) ページで [Connect existing subscription]\(既存のサブスクリプションに接続する\) を選択します。

     ![既存のサブスクリプションに接続する](media/custom-voice/connect-existing-sub.png)

4. 次に示すように、テーブルにサブスクリプション キーを貼り付けます。 各サブスクリプションには 2 つのキーがあり、どちらを使用してもかまいません。

     ![サブスクリプションを追加する](media/custom-voice/add-subscription.png)

準備ができました。

## <a name="prepare-recordings-and-transcripts"></a>録音とトランスクリプトを準備する

音声トレーニング データセットは、オーディオ ファイルのセットと、すべてのオーディオ ファイルのトランスクリプトを含むテキスト ファイルで構成されます。

これらのファイルは、どちらの方向でも準備できます。つまり、スクリプトを記述し、音声タレントに読んでもらうか、または一般に使用可能なオーディオを使用し、それをテキストに文字起こしするかのどちらでもかまいません。 後者の場合は、"うーん" のような口ごもり、その他の間つなぎ音、言葉の詰まり、聞き取りにくい単語、間違った発音を、オーディオ ファイルから編集します。

良質の音声フォントを作成するには、静かな部屋で高品質のマイクを使って録音を行うことが重要です。 一定の音量、速さ、ピッチ、および表現方法で話すことが、優れたデジタル音声の作成には不可欠です。 製品用の音声を作成するには、専門の録音スタジオと音声タレントを使うことをお勧めします。 詳細については、[カスタム音声用の音声サンプルを録音する方法](record-custom-voice-samples.md)に関するページを参照してください。

### <a name="audio-files"></a>オーディオ ファイル

各オーディオ ファイルには、1 つの発話が含まれる必要があります (1 つの文、対話システムの 1 つのターンなど)。 すべてのファイルは同じ言語でなければなりません (複数言語のカスタム音声はサポートされていません)。 また、オーディオ ファイルにはファイル名拡張子が `.wav` の一意の数値ファイル名が付いている必要があります。

オーディオ ファイルは次のように準備する必要があります。 他の形式はサポートされておらず、拒否されます。

| **プロパティ** | **値** |
| ------------ | --------- |
| ファイル形式  | RIFF (WAV)|
| サンプル速度| 少なくとも 16,000 Hz |
| サンプル形式| PCM、16 ビット |
| ファイル名    | 数値、拡張子は `.wav` |
| アーカイブ形式| ZIP      |
| 最大アーカイブ サイズ|200 MB|

オーディオ ファイルのセットをサブディレクトリのない 1 つのフォルダーに格納し、セット全体を 1 つの ZIP ファイル アーカイブとしてパッケージ化します。

> [!NOTE]
> サンプリング レートが 16,000 Hz より低い Wave ファイルは拒否されます。 zip ファイルにサンプリング レートが異なる波が含まれている場合は、16,000 Hz 以上の波だけがインポートされます。
> 現在、ポータルは最大 200 MB の ZIP アーカイブをインポートします。 ただし、複数のアーカイブをアップロードできます。 許可されるデータセットの最大数は、Free サブスクリプション ユーザーの場合は ZIP ファイル 10 個、Standard サブスクリプション ユーザーの場合は 50 個です。

### <a name="transcripts"></a>トランスクリプト

文字起こしファイルはプレーンテキスト ファイル (ANSI/UTF-8/UTF-8-BOM/UTF-16-LE/UTF-16-BE) です。 文字起こしファイルの各行は、オーディオ ファイルの名前、タブ (コード ポイント 9) 文字、トランスクリプトという順序になっている必要があります。 空白行は許可されていません。

例: 

```
0000000001  This is the waistline, and it's falling.
0000000002  We have trouble scoring.
0000000003  It was Janet Maslin.
```

カスタム音声システムは、テキストを小文字に変換し、余分な区切り記号を削除することで、トランスクリプトを正規化します。 対応するオーディオ録音に対してトランスクリプトが 100% 正確であることが重要です。

> [!TIP]
> 製品用のテキスト読み上げ音声を作成するときは、音声の範囲と効率性の両方を考慮して発話 (または記述スクリプト) を選択します。

## <a name="upload-your-datasets"></a>データセットをアップロードする

オーディオ ファイルのアーカイブとトランスクリプトの準備ができたら、[Custom Voice サービス ポータル](https://customvoice.ai)でアップロードします。

> [!NOTE]
> アップロードした後は、データセットを編集できません。 たとえば、一部のオーディオ ファイルのトランスクリプトを収め忘れた場合や、誤って間違った性別を選んだ場合などは、データセット全体をもう一度アップロードする必要があります。 アップロードを開始する前に、データセットと設定をよく確認してください。

1. ポータルにサインインします。

2. メイン ページの [Custom Voice] の下の **[Data]\(データ\)** を選択します。 

    ![マイ プロジェクト](media/custom-voice/my-projects.png)

    [My Voice Data]\(マイ音声データ\) テーブルが表示されます。 音声データセットをまだアップロードしていない場合は空です。

3. **[Import data]\(データのインポート\)** をクリックして、新規データセット アップロード用のページを開きます。

    ![音声データをインポートする](media/custom-voice/import-voice-data.png)

4. 表示されたフィールドに名前と説明を入力します。 

5. 音声フォントのロケールを選択します。 ロケール情報が録音データおよびスクリプトの言語と一致することを確認します。 

6. 音声を使用している話者の性別を選択します。

7. アップロードするスクリプト ファイルとオーディオ ファイルを選択します。 

8. **[Import]\(インポート\)** をクリックしてデータをアップロードします。 大きいデータ セットでは、インポートに数分かかることがあります。

> [!NOTE]
> Free サブスクリプション ユーザーは、一度に 2 個のデータセットをアップロードできます。 Standard サブスクリプション ユーザーは、5 個のデータセットを同時にアップロードできます。 制限に達した場合は、少なくとも 1 つのデータセットのインポートが終わるまで待ってから、もう一度やり直します。

アップロードが完了すると、[My Voice Data]\(マイ音声データ\) テーブルが再び表示されます。 アップロードしたデータセットに対応するエントリが表示されます。 

アップロードの完了後に、データセットは自動的に検証されます。 データ検証には、ファイル形式、サイズ、サンプル速度を確認する、オーディオ ファイルの一連のチェックが含まれます。 文字起こしファイルのチェックでは、ファイル形式が確認され、いくつかのテキストの正規化が実行されます。 発話が音声認識を使用して文字起こしされ、結果のテキストが提供されたトランスクリプトと比較されます。

![マイ音声データ](media/custom-voice/my-voice-data.png)

次の表では、インポートされたデータセットの処理状態を示します。 

| State | 意味
| ----- | -------
| `NotStarted` | データセットは受信され、処理のためにキューに入れられています
| `Running` | データセットは検証されています
| `Succeeded` | データセットは検証が済み、音声フォントの作成に使用できます

検証が完了すると、各データセットで一致した発話の合計数を [Utterance]\(発話\) 列で確認できます。

レポートをダウンロードして、各録音の発音スコアとノイズ レベルを確認できます。 発音スコアの範囲は 0 ～ 100 です。スコアが 70 未満の場合は、通常、音声認識のエラーまたはスクリプトの不一致を示します。 アクセントが強いと発音スコアが下がることがあり、生成されるデジタル音声に影響します。

高い信号雑音比 (SNR) は、オーディオのノイズが低いことを示します。 通常、専門のスタジオで録音することにより、SNR を 50 以上にできます。 SNR が 20 未満のオーディオでは、生成される音声に明らかなノイズが含まれる可能性があります。

発音スコアが低い場合や SNR が悪い場合は、発話を録音し直すことを検討してください。 再録音が不可能な場合は、データセットからその発話を除外してもかまいません。

## <a name="build-your-voice-font"></a>音声フォントを作成する

データセットの検証が済むと、それを使用してカスタム音声フォントを作成できます。 

1. [Custom Voice] ドロップダウン メニューの **[Models]\(モデル\)** を選択します。 
 
    [My Voice Fonts]\(マイ音声フォント\) テーブルに、既に作成されているカスタム音声フォントの一覧が表示されます。

1. テーブル タイトルの下にある **[Create voices]\(音声の作成\)** をクリックします。 

    音声フォント作成ページが表示されます。 テーブルの 1 行目には、現在のロケールが表示されます。 別の言語で音声を作成するには、ロケールを変更します。 ロケールは、音声の作成に使用されるデータセットと同じである必要があります。

1. データセットをアップロードしたときと同様に、このモデルを識別するのに役立つ説明と名前を入力します。 

    ここで入力する名前は、SSML 入力の一部として音声合成を要求するときに音声の指定で使う名前になるので、慎重に選択してください。 文字、数字、およびいくつかの区切り文字 "-"、"_"、"("、")" だけを使用できます。

    説明フィールドの一般的な用途は、モデルの作成に使用されたデータセットの名前を記録することです。

1. 音声フォントの性別を選択します。 データセットの性別と一致している必要があります。

1. 音声フォントのトレーニングに使用するデータセットを選択します。 使用するすべてのデータセットが、同じ話者である必要があります。

1. **[Create]\(作成\)** をクリックして、音声フォントの作成を開始します。

    ![モデルの作成](media/custom-voice/create-model.png)

新しいモデルが [My Voice Fonts]\(マイ音声フォント\) テーブルに表示されます。 

![[My Voice Fonts]\(マイ音声フォント\)](media/custom-voice/my-voice-fonts.png)

表示される状態は、次に示すように、データセットから音声フォントへの変換プロセスを反映しています。

| State | 意味
| ----- | -------
| `NotStarted` | 音声フォント作成要求は、処理のためにキューに置かれました。
| `Running` | 音声フォントを作成中です。
| `Succeeded` | 音声フォントは作成が済み、展開できます。

トレーニング時間は、処理されるオーディオ データの量によって異なります。 標準的な時間は、数百個の発話で約 30 分、20,000 個の発話で 40 時間です。

> [!NOTE]
> Free サブスクリプション ユーザーは、一度には 1 つの音声フォントをトレーニングできます。 Standard サブスクリプション ユーザーは、3 つの音声を同時にトレーニングできます。 制限に達した場合は、少なくとも 1 つの音声フォントのトレーニングが終わるまで待ってから、もう一度やり直します。

## <a name="test-your-voice-font"></a>音声フォントをテストする

音声フォントが正常に作成されたら、使用するために展開する前にテストできます。 [Operations]\(操作\) 列の **[Test]\(テスト\)** をクリックします。 選択した音声フォントのテスト ページが表示されます。 その音声のテスト要求をまだ送信していない場合、テーブルは空です。

![[My Voice Fonts]\(マイ音声フォント\)、パート 2](media/custom-voice/my-voice-fonts2.png)

テーブル タイトルの下にある **[Test with text]\(テキストをテストする\)** ボタンをクリックすると、テキスト要求送信用のポップアップ メニューが表示されます。 プレーン テキストまたは SSML でテスト要求を送信できます。 最大入力サイズは、SSML 要求のすべてのタグを含めて、1,024 文字です。 テキストの言語は、音声フォントの言語と同じである必要があります。

![音声フォントのテスト](media/custom-voice/voice-font-testing.png)

テキスト ボックスに入力して入力モードを確認した後、**[はい]** をクリックしてテスト要求を送信し、テスト ページに戻ります。 テーブルには、新しい要求に対応するエントリと、もうおなじみになった状態列が表示されます。 音声の合成には数分かかる場合があります。 状態列に [Succeeded]\(成功\) と表示されたら、テキスト入力 (`.txt` ファイル) とオーディオ出力 (`.wav` ファイル) をダウンロードし、後者の品質を試聴できます。

![音声フォントのテスト、パート 2](media/custom-voice/voice-font-testing2.png)

## <a name="create-and-use-a-custom-endpoint"></a>カスタム エンドポイントを作成して使用する

音声モデルの作成とテストが正常に終了したら、カスタム Text to Speech エンドポイントに展開します。 その後は、REST API で Text to Speech 要求を行うときの通常のエンドポイントの代わりに、このエンドポイントを使います。 カスタム エンドポイントは、フォントを展開するときに使ったサブスクリプションからのみ呼び出すことができます。

新しいカスタム エンドポイントを作成するには、ページ上部の [Custom Voice] メニューから **[エンドポイント]** を選択します。 [展開された音声] ページが表示され、現在のカスタム音声エンドポイントのテーブルが示されます (存在する場合)。 そのテーブルの 1 行目に現在のロケールが反映されています。 別の言語の展開を作成するには、表示されているロケールを変更します。 (展開している音声と一致する必要があります。)

**[Deploy voices]\(音声の展開\)** ボタンをクリックして、新しいエンドポイントを作成します。 カスタム エンドポイントの名前と説明を入力します。

[サブスクリプション] メニューで、使用するサブスクリプションを選択します。 Free サブスクリプション ユーザーは、一度に 1 つだけモデルを展開できます。 Standard サブスクリプション ユーザーは、それぞれが独自のカスタム音声を使用する最大 20 個のエンドポイントを作成できます。

![エンドポイントを作成する](media/custom-voice/create-endpoint.png)

展開するモデルを選択した後、**[Create]\(作成\)** をクリックします。 [展開された音声] ページが再び表示され、今度は新しいエンドポイントのエントリが示されます。 新しいエンドポイントのインスタンス化には、数分かかることがあります。 展開の状態が [Succeeded]\(成功\) の場合、エンドポイントは使用可能です。

![展開された音声](media/custom-voice/my-deployed-voices.png)

展開の状態が [成功] である場合は、展開された音声フォントのエンドポイントが [展開された音声] テーブルに表示されます。 この URI を HTTP 要求内で直接使用できます。

Custom Voice ポータルを使用して、エンドポイントのオンライン テストを行うこともできます。 エンドポイントをテストするには、[Custom Voice] ドロップダウン メニューから **[Endpoints testing]\(エンドポイントのテスト\)** を選択します。 エンドポイントのテスト ページが表示されます。 展開されたカスタム音声を選択し、読み上げるテキストをテキスト ボックスに (プレーンテキストまたは SSML 形式のどちらかで) 入力します。

> [!NOTE] 
> SSML を使用するときは、`<voice>` タグでカスタム音声の作成時に設定した名前を指定する必要があります。

**[Play]\(再生\)** をクリックし、カスタム音声フォントで読み上げられるテキストを聞きます。

![エンドポイントのテスト](media/custom-voice/endpoint-testing.png)

カスタム エンドポイントの機能は、テキスト読み上げ要求に使用される標準のエンドポイントと同じです。 詳しくは、[REST API](rest-apis.md) に関するページをご覧ください。

## <a name="next-steps"></a>次の手順

- [Speech 試用版サブスクリプションを取得する](https://azure.microsoft.com/try/cognitive-services/)
- [C# で音声を認識する](quickstart-csharp-dotnet-windows.md)
