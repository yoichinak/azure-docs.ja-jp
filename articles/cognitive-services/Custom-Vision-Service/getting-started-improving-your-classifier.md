---
title: Custom Vision Service を使用して分類器を改善する - Azure Cognitive Services | Microsoft Docs
description: Custom Vision Service 分類器の品質を改善する方法について説明します。
services: cognitive-services
author: noellelacharite
manager: nolachar
ms.service: cognitive-services
ms.component: custom-vision
ms.topic: article
ms.date: 07/05/2018
ms.author: nolachar
ms.openlocfilehash: 7c6cbd996d0c35b96fde78daf391bebb36feddce
ms.sourcegitcommit: 11321f26df5fb047dac5d15e0435fce6c4fde663
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 07/06/2018
ms.locfileid: "37888182"
---
# <a name="how-to-improve-your-classifier"></a>分類器を改善する方法

Custom Vision Service 分類器の品質を改善する方法について説明します。 分類器の品質は、そこに提供するラベル付きデータの量、品質、多様性や、データセットのバランスがどれだけとれているかに依存します。 適切な分類器には通常、その分類器に送信されるものを代表する、バランスのとれたトレーニング データセットがあります。 このような分類器を構築するプロセスは、多くの場合、反復的なプロセスです。 予期される結果に達するには、数回のトレーニングが必要になることが一般的です。

分類器を改善するために実行される一般的な手順を次に示します。 この手順は厳格な規則ではなく、より適切な分類器を構築するために役立つヒューリスティックです。

1. 1 回目のトレーニング
1. さらに画像を追加し、データのバランスをとる
1. 再トレーニング
1. 背景、照明、オブジェクト サイズ、カメラ アングル、スタイルがさまざまな画像を追加する
1. 再トレーニングし、予測のために画像を取り込む
1. 予測結果を検証する
1. 既存のトレーニング データを変更する

## <a name="data-quantity-and-data-balance"></a>データの量とデータのバランス

最も重要な点は、分類器をトレーニングするために十分な画像をアップロードすることです。 出発点として、トレーニング セットのラベルあたり少なくとも 50 の画像が推奨されます。 画像の数が少ないと、過剰適合するリスクが大きくなります。 パフォーマンスの数値は良い品質を示すことがありますが、実世界のデータに対して苦労する可能性があります。 さらに多くの画像を使用して分類器をトレーニングすると、一般には予測結果の精度が向上します。

もう 1 つの考慮事項として、データのバランスがとれていることを確認する必要があります。 たとえば、あるラベルに 500 の画像があり、別のラベルに 50 の画像がある場合は、生成されるトレーニング データセットのバランスが悪く、そのモデルはあるラベルの予測が別のラベルの予測より正確になります。 画像が最も少ないラベルと画像が最も多いラベルの間で少なくとも 1:2 の比率を維持すれば、より優れた結果が得られる可能性があります。 たとえば、画像が最も多いラベルに 500 の画像がある場合、画像が最も少ないラベルにはトレーニングのために少なくとも 250 の画像が必要です。

## <a name="train-more-diverse-images"></a>より多様な画像をトレーニングする

通常の使用中に分類器に送信されるものを代表する画像を提供してください。 たとえば、"リンゴ" の分類器をトレーニングしている場合、お皿にあるリンゴの写真のみをトレーニングしたのに、木になっているリンゴの写真で予測を行うと、分類器はそれほど正確でない可能性があります。 多様な画像を含めると、分類器が偏らず、適切に一般化できるようになります。 トレーニング セットをより多様にするために実行できるいくつかの方法を次に示します。

__背景:__ さまざまな背景の前にあるオブジェクトの画像 (たとえば、お皿にある果物に対して、食料品バッグの中の果物) を提供します。 状況が写った写真は、分類器により詳細な情報を提供するため、中立の背景の前にある写真より優れています。

![背景のサンプルの画像](./media/getting-started-improving-your-classifier/background.png)

__照明:__ 特に、予測に使用される画像にさまざまな照明が含まれている場合は、照明が多様な (たとえば、フラッシュで撮られた、露出が高いなど) 画像を提供します。 これはまた、彩度、色相、および輝度が多様な画像を含めるためにも役立ちます。

![照明のサンプルの画像](./media/getting-started-improving-your-classifier/lighting.png)

__オブジェクト サイズ:__ オブジェクトのサイズが多様で、オブジェクトのさまざまな部分がキャプチャされている画像を提供します。 たとえば、一房のバナナの写真や、1 本のバナナの大写しなどです。 さまざまなサイズは、分類器がより適切に一般化するのに役立ちます。

![サイズのサンプルの画像](./media/getting-started-improving-your-classifier/size.png)

__カメラ アングル:__ さまざまなカメラ アングルで撮られた画像を提供します。 すべての写真が一連の固定されたカメラ (防犯カメラなど) で撮られている場合は、過剰適合、つまり、関連のないオブジェクト (街灯柱など) を重要な特徴としてモデル化することを回避するために、同じオブジェクトをキャプチャしている場合でもすべてのカメラに異なるラベルを割り当てるようにしてください。

![アングルのサンプルの画像](./media/getting-started-improving-your-classifier/angle.png)

__スタイル:__ 同じクラスのさまざまなスタイル (たとえば、さまざまな種類の柑橘類) の画像を提供します。 ただし、スタイルが極端に異なるオブジェクトの画像 (たとえば、ミッキー マウスに対して実物のネズミ) がある場合は、その個別の特徴をより適切に表すために、それらに別のクラスとしてラベルを付けることをお勧めします。

![スタイルのサンプルの画像](./media/getting-started-improving-your-classifier/style.png)

## <a name="use-images-submitted-for-prediction"></a>予測のために送信されたイメージを使用する

Custom Vision Service は、予測エンドポイントに送信されたイメージを保存しています。 分類器を改善するためにこれらのイメージを使用するには、次の手順を使用します。

1. 分類器に送信された画像を表示するには、[Custom Vision Web ページ](https://customvision.ai)を開き、プロジェクトに移動して __[予測]__ タブを選択します。既定のビューには、現在のイテレーションのイメージが表示されます。 __[Iteration]__(イテレーション) ドロップ ダウン フィールドを使用すると、以前のイテレーションで送信されたイメージを表示できます。

    ![予測タブのイメージ](./media/getting-started-improving-your-classifier/predictions.png)

2. イメージの上にポインターを置き、分類器が予測したタグを表示します。 画像は、分類器に最も大きな利益を提供できる画像が一番上になるように順位付けされます。 異なる並べ替えを選択するには、__[Sort]__(並べ替え) セクションを使用します。 既存のトレーニング データに画像を追加するには、画像を選択し、正しいタグを選択して __[保存して閉じる]__ をクリックします。 画像が __[予測]__ から削除され、トレーニング画像に追加されます。 __[Training Images]__(トレーニング イメージ) タブを選択すると、これを表示できます。

    ![タグ付けページのイメージ](./media/getting-started-improving-your-classifier/tag.png)

3. __[Train]__(トレーニング) ボタンを使用して、分類器を再トレーニングします。

## <a name="visually-inspect-predictions"></a>予測を視覚的に検査する

イメージの予測を検査するには、選択、__[Training Images]__(トレーニング イメージ) タブを選択してから、__[Iteration History]__(イテレーション履歴) を選択します。 赤いボックスで囲まれているイメージは、正しく予測されました。

![イテレーション履歴のイメージ](./media/getting-started-improving-your-classifier/iteration.png)

視覚的な検査により、その後でさらにトレーニング データを追加するか、または既存のトレーニング データを変更することによって修正できるパターンを識別できる場合があります。 たとえば、リンゴとライムを区別する分類器によって、すべての緑色のリンゴに誤ってライムとしてラベルが付けられる可能性があります。 この問題は、緑色のリンゴのタグ付きの画像を含むトレーニング データを追加および提供することによって修正できる可能性があります。

## <a name="unexpected-classification"></a>予期しない分類

画像に共通に含まれている特性を分類器が誤って学習する場合があります。 たとえば、リンゴと柑橘類を区別する分類器を作成しており、手の中のリンゴの画像と白いお皿にある柑橘類の画像が提供されている場合、その分類器はリンゴと柑橘類ではなく、手と白いお皿を区別するようにトレーニングされる可能性があります。

![予期しない分類の画像](./media/getting-started-improving-your-classifier/unexpected.png)

この問題を修正するには、より多様な画像を使用したトレーニングに関する上のガイダンスを使用し、さまざまなアングル、背景、オブジェクト サイズ、グループ、およびその他の変種を含む画像を提供します。

## <a name="negative-image-handling"></a>イメージの否定処理

Custom Vision Service サービスは、イメージの自動否定処理をいくつかサポートしています。 ブドウとバナナを区別する分類器を構築しており、予測のために片方の靴の画像を送信した場合、その分類器はブドウとバナナの両方について、その画像に 0% に近いスコアを付けるはずです。

これに対して、否定画像がトレーニングで使用された画像の変動にすぎない場合は、その大きな類似点のために、モデルがその否定画像をラベル付きのクラスとして分類する可能性があります。 たとえば、オレンジとグレープフルーツを区別する分類器があり、クレメンタインの画像を取り込んだ場合、その分類器はクレメンタインにオレンジとしてスコアを付ける可能性があります。 これは、クレメンタインの多くの特徴 (色、形、肌触り、自然の生息地など) がオレンジの特徴に似ているために発生することがあります。  否定画像がこれと同じ性質である場合は、1 つ以上の個別のタグ ([その他]) を作成し、トレーニング中に否定画像にこのタグのラベルを付けて、モデルがこれらのクラスをより適切に区別できるようにすることをお勧めします。

## <a name="next-steps"></a>次の手順

画像を予測 API に送信することによって、それらの画像をプログラムでテストする方法を学習します。

> [!div class="nextstepaction"]
[予測 API の使用](use-prediction-api.md)
