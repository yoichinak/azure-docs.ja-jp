---
title: Azure Media Services の Fragmented MP4 ライブ インジェスト仕様 | Microsoft Docs
description: この仕様では、Azure Media Services 用 Fragmented MP4 ベースのライブ ストリーミング インジェストのプロトコルと形式について説明します。 Azure Media Services では、Azure をクラウド プラットフォームとして使用することにより、ライブ イベントのストリーミング配信とリアルタイムでのコンテンツのブロードキャストを行うことができます。 このドキュメントでは、冗長性の高い、堅牢なライブ インジェスト メカニズムを構築する上でのベスト プラクティスについても説明します。
services: media-services
documentationcenter: ''
author: cenkdin
manager: cfowler
editor: ''
ms.assetid: 43fac263-a5ea-44af-8dd5-cc88e423b4de
ms.service: media-services
ms.workload: media
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 06/29/2017
ms.author: cenkd;juliako
ms.openlocfilehash: 88c152872ef8b571b8bc3e3f06ce486943e724b1
ms.sourcegitcommit: 1d850f6cae47261eacdb7604a9f17edc6626ae4b
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 08/02/2018
ms.locfileid: "39443530"
---
# <a name="azure-media-services-fragmented-mp4-live-ingest-specification"></a>Azure Media Services の Fragmented MP4 ライブ インジェスト仕様
この仕様では、Azure Media Services 用 Fragmented MP4 ベースのライブ ストリーミング インジェストのプロトコルと形式について説明します。 Media Services は、顧客が Azure をクラウド プラットフォームとして使用して、ライブ イベントをストリーム配信し、リアルタイムでコンテンツをブロードキャストできるライブ ストリーミング サービスを提供しています。 このドキュメントでは、冗長性の高い、堅牢なライブ インジェスト メカニズムを構築する上でのベスト プラクティスについても説明します。

## <a name="1-conformance-notation"></a>1.適合性の表記
このドキュメントで使用するキーワード "MUST (しなければなりません)"、"MUST NOT (してはなりません)"、"REQUIRED (必要です)"、"SHALL (することになります)"、"SHALL NOT (することはありません)"、"SHOULD (する必要があります)"、"SHOULD NOT (すべきではありません)"、"RECOMMENDED (お勧めします)"、"MAY (する場合があります)"、"OPTIONAL (オプション)" は、RFC 2119 で説明するとおりに解釈されます。

## <a name="2-service-diagram"></a>2.サービス図
次の図は、Media Services でのライブ ストリーミング サービスの大まかなアーキテクチャを示しています。

1. ライブ エンコーダーによって、Azure Media Services SDK を使用して作成、プロビジョニングされるチャネルにライブ フィードがプッシュされます。
1. Media Services のチャネル、プログラム、ストリーミング エンドポイントで、インジェスト、書式設定、クラウド DVR、セキュリティ、スケーラビリティ、冗長性などのすべてのライブ ストリーミングの機能を処理します。
1. オプションで、ストリーミング エンドポイントとクライアント エンドポイント間に Microsoft Azure Content Delivery Network 層をデプロイすることもできます。
1. クライアント エンドポイントは HTTP アダプティブ ストリーミング プロトコルを使用してストリーミング エンドポイントからストリームします。 例としては、Microsoft スムーズ ストリーミング、Dynamic Adaptive Streaming over HTTP (DASH または MPEG-DASH)、Apple HTTP ライブ ストリーミング (HLS) があります。

![インジェスト フロー][image1]

## <a name="3-bitstream-format--iso-14496-12-fragmented-mp4"></a>手順 3.ビットストリーム形式 – ISO 14496-12 Fragmented MP4
このドキュメントで言及するライブ ストリーミング インジェスト用のワイヤ形式は、[ISO-14496-12] に基づきます。 Fragmented MP4 形式、ビデオ オンデマンド ファイルの拡張子、ライブ ストリーミング インジェストの詳細については、[[MS-SSTR]](http://msdn.microsoft.com/library/ff469518.aspx) に関するページをご覧ください。

### <a name="live-ingest-format-definitions"></a>ライブ インジェスト形式の定義
Azure Media Services にライブ インジェストを適用する特殊形式の定義の一覧を次に示します。

1. **ftyp**、**Live Server Manifest Box**、**moov** ボックスは、各要求 (HTTP POST) と共に送信しなければなりません。 これらのボックスをストリームの開始時に送信し、ストリームの取り込みを再開するたびにエンコーダーを再接続しなければなりません。 詳細については、[1] のセクション 6 をご覧ください。
1. [1] のセクション 3.3.2 では、**StreamManifestBox** と呼ばれるオプションのボックスをライブ インジェストに定義します。 Azure ロード バランサーのルーティング ロジックにより、このボックスの使用は非推奨になりました。 このボックスは Media Services へのインジェスト時に存在すべきではありません。 このボックスが存在しても、Media Services は何も行わずに無視します。
1. [1] の 3.2.3.2 で定義された **TrackFragmentExtendedHeaderBox** ボックスは、各フラグメントに存在しなければなりません。
1. **TrackFragmentExtendedHeaderBox**ボックスのバージョン 2 は、複数のデータセンターで同一の URL を使用するメディア セグメントを生成するために使用する必要があります。 フラグメントのインデックス フィールドは、Apple HLS や インデックス ベースの MPEG DASH などのインデックス ベースのストリーミング形式のデータセンター間のフェールオーバーで必要です。 データセンター間のフェールオーバーを有効にするには、フラグメントのインデックスを複数のエンコーダー間で同期しなければなりません。また、エンコーダーが再起動または失敗した場合でも、連続するメディア フラグメントごとにフラグメントのインデックスを 1 ずつ増やさなければなりません。
1. [1] のセクション 3.3.6 では、チャネルに EOS (ストリームの終わり) を示すためにライブ インジェストの最後に送信される場合がある、**MovieFragmentRandomAccessBox** (**mfra**) というボックスを定義します。 Media Services のインジェスト ロジックにより、EOS (ストリームの終わり) の使用は非推奨になりました。ライブ インジェストの **mfra** ボックスを送信すべきではありません。 送信されても、Media Services は何も行わずに無視します。 取り込みポイントの状態をリセットするには、[Channel のリセット](https://docs.microsoft.com/rest/api/media/operations/channel#reset_channels)の使用をお勧めします。 また、プレゼンテーションとストリームを終了するには、[Program の停止](https://msdn.microsoft.com/library/azure/dn783463.aspx#stop_programs)の使用をお勧めします。
1. MP4 フラグメントの継続時間は、クライアント マニフェストのサイズを小さくするために定数にする必要があります。 MP4 フラグメントの継続時間を定数にすることで、繰り返しタグの使用によりクライアントのダウンロードのヒューリスティックも改善されます。 整数以外のフレーム レートを補正するため、継続時間は変動する場合があります。
1. MP4 フラグメントの継続時間は約 2 ～ 6 秒間にする必要があります。
1. MP4 フラグメントのタイムスタンプとインデックス (**TrackFragmentExtendedHeaderBox** `fragment_ absolute_ time` と `fragment_index`) は昇順で配信される必要があります。 Media Services は、重複フラグメントに対する回復力はありますが、メディア タイムラインに従ってフラグメントの順序を変更するには機能が限定されています。

## <a name="4-protocol-format--http"></a>4.プロトコル形式 - HTTP
Media Services 用 ISO Fragmented MP4 ベースのライブ インジェストは、標準の長期間実行される HTTP POST 要求を使用して、Fragmented MP4 形式でパッケージ化されたエンコード済みメディア データをサービスに送信します。 各 HTTP POST は完全な Fragmented MP4 ビットストリーム ("stream") を送信します。これは、ヘッダー ボックス (**ftyp**、**Live Server Manifest Box**、**moov** ボックス) で開始し、フラグメント (**moof** ボックスと **mdat** ボックス) のシーケンスで継続します。 HTTP POST 要求の URL 構文については、[1] のセクション 9.2 をご覧ください。 POST URL の例は次のとおりです。 

    http://customer.channel.mediaservices.windows.net/ingest.isml/streams(720p)

### <a name="requirements"></a>必要条件
要件の詳細を以下に示します。

1. エンコーダーは、同じインジェスト URL を使用して空の「本文」(コンテンツの長さが 0) で HTTP POST 要求を送信し、ブロードキャストを開始する必要があります。 これにより、エンコーダーがライブ インジェストのエンドポイントが有効であるかどうかや、認証などの条件が必要であるかどうかをすばやく検出できます。 HTTP プロトコルに従って、サーバーは POST の本文を含む要求全体を受信するまで、HTTP 応答を返信できません。 ライブ イベントの実行時間が長いことからも、この手順を行わないと、すべてのデータ送信を終了するまでは、エンコーダーでエラーを検出できない場合があります。
1. エンコーダーは、すべてのエラーや、(1) によって発生した認証チャレンジを処理しなければなりません。 (1) が 200 の応答に成功すると、処理を続行します。
1. エンコーダーは、Fragmented MP4 ストリームで新しい HTTP POST 要求を開始しなければなりません。 ペイロードはヘッダー ボックスで開始し、その後にフラグメントが続かなければなりません。 ストリームの終了前に前回の要求が終了したためエンコーダーを再接続しなければならない場合でも、**ftyp**、**Live Server Manifest Box**、**moov** ボックスを (この順序で) 各要求とともに送信しなければならないことにご注意ください。 
1. ライブ イベントのコンテンツ全体の長さを予測することは不可能なので、エンコーダーは、アップロードにチャンク転送エンコードを使用しなければなりません。
1. イベントが終了すると、最後のフラグメントの送信後に、エンコーダーはチャンク転送エンコードのメッセージ シーケンス (ほとんどの HTTP クライアント スタックで自動的に処理されます) を正常に終了しなければなりません。 エンコーダーは、サービスが最後の応答コードを返し、接続を終了するのを待機しなければなりません。 
1. [1] の 9.2 で説明するとおり、エンコーダーは、`Events()` 名詞を Media Services へのライブ インジェストに使用してはなりません。
1. ストリームが終了する前に HTTP POST 要求が終了するか、TCP エラーを伴ってタイムアウトが発生する場合、エンコーダーは、新しい接続を使用して新しい POST 要求を発行し、前述の要件に従わなければなりません。 さらに、エンコーダーは、ストリームの各トラックに対する前回の 2 つの MP4 フラグメントを再送信し、メディア タイムラインに不連続性を発生させずに再開しなければなりません。 トラックごとに最後の 2 つの MP4 フラグメントを再送信することで、データが失われることはなくなります。 つまり、オーディオとビデオ トラックの両方が含まれるストリームで現在の POST 要求が失敗した場合、データが失われないように、エンコーダーは再接続して、前回正常に送信されたオーディオ トラックとビデオ トラックの最後の 2 つのフラグメントをぞれぞれ再送信しなければなりません。 エンコーダーは、再接続時に再送するメディア フラグメントの「早送り」バッファーを維持しなければなりません。

## <a name="5-timescale"></a>5.タイムスケール
[[MS-SSTR]](https://msdn.microsoft.com/library/ff469518.aspx) に関するページでは、**SmoothStreamingMedia** (セクション 2.2.2.1)、**StreamElement** (セクション 2.2.2.3)、**StreamFragmentElement**(セクション 2.2.2.6)、**LiveSMIL** (セクション 2.2.7.3.1) のタイムスケールの使用方法について説明します。 タイムスケールの値が存在しない場合、使用される既定値は 10,000, 000 (10 MHz) です。 その他のタイムスケール値の使用は Smooth Streaming 形式の仕様によってブロックされませんが、ほとんどのエンコーダーの実装ではこの既定値 (10 MHz) を使用して Smooth Streaming のインジェスト データを生成します。 [Azure Media ダイナミック パッケージ](media-services-dynamic-packaging-overview.md)機能により、ビデオ ストリームには 90 kHz、オーディオ ストリームには 44.1 kHz または 48.1 kHz のタイムスケールを使用することをお勧めします。 ストリームによって異なるタイムスケールの値を使用すると、ストリーム レベルのタイムスケールを送信しなければなりません。 詳細については、[[MS-SSTR]](https://msdn.microsoft.com/library/ff469518.aspx) に関するページを参照してください。     

## <a name="6-definition-of-stream"></a>6.「ストリーム」の定義
「ストリーム」とは、ライブ プレゼンテーションを構成するためのライブ インジェスト操作の基本単位です。ストリーム フェールオーバーや冗長性シナリオを処理します。 「ストリーム」は、1 つ以上のトラックが含まれる 1 つの固有の Fragmented MP4 ビットストリームとして定義されます。 完全なライブ プレゼンテーションには、ライブ エンコーダーの構成に応じて 1 つ以上のストリームが含まれます。 次の例では、ストリームを使用して完全なライブ プレゼンテーションを構成するさまざまなオプションについて説明します。

**例:** 

顧客の目的は、次のオーディオ ビットレートとビデオ ビットレートによるライブ ストリーミングのプレゼンテーションを作成することです。

ビデオ – 3000 kbps、1500 kbps、750 kbps

オーディオ – 128 kbps

### <a name="option-1-all-tracks-in-one-stream"></a>オプション 1: すべてのトラックを 1 つのストリームに配置する
このオプションでは、1 つのエンコーダーですべてのオーディオ トラックとビデオ トラックを生成し、1 つの Fragmented MP4 ビットストリームにバンドルします。 Fragmented MP4 ビットストリームは、その後、1 つの HTTP POST 接続を経由して送信されます。 この例では、このライブ プレゼンテーションには 1 つのストリームだけがあります。

![1 ストリームのトラック][image2]

### <a name="option-2-each-track-in-a-separate-stream"></a>オプション 2: 各トラックを個別のストリームに配置する
このオプションでは、エンコーダーは各 Fragment MP4 ビットストリームにトラックを 1 つずつ配置して、すべてのストリームを個別の HTTP 接続を経由して送信します。 これは、1 つのエンコーダーでも複数のエンコーダーでも実行できます。 ライブ インジェストの観点では、このライブ プレゼンテーションは次の 4 つのストリームで構成されます。

![個別ストリームのトラック][image3]

### <a name="option-3-bundle-audio-track-with-the-lowest-bitrate-video-track-into-one-stream"></a>オプション 3: 最も低いビットレートのビデオ トラックにオーディオ トラックをバンドルし 1 つのストリームに配置する
このオプションでは、顧客は最も低いビットレートのビデオ トラックとオーディオ トラックを 1 つの Fragment MP4 ビットストリームにバンドルし、その他の 2 つのビデオ トラックは個別のストリームとして残しています。 

![オーディオ トラックとビデオ トラックのストリーム][image4]

### <a name="summary"></a>まとめ
この例で実現可能なすべてのインジェスト オプションを網羅しているわけではありません。 実際、ストリームへのトラックのすべてのグループ化がライブ インジェストでサポートされています。 顧客とエンコーダーのベンダーは、エンジニアリングの複雑さ、エンコーダーの容量、冗長性、フェールオーバーに関する考慮事項に基づいて、独自の実装を選択できます。 ただし、ライブ プレゼンテーション全体に対してオーディオ トラックは 1 つだけである場合がほとんどです。 オーディオ トラックを格納するインジェスト ストリームの正常な稼働状態を確保することが重要です。この点を考慮すると、オーディオ トラックを単独のストリームに配置するか (オプション 2)、最も低いビットレートのビデオ トラックとバンドルする (オプション 3) ことになります。 また、冗長性とフォールト トレランスを改善するために、Media Services でのライブ インジェストには、同じオーディオ トラックを 2 つの異なるストリームで送信するか (オプション 2: 冗長オーディオ トラック)、オーディオ トラックを最も低いビットレートの 2 つ以上のビデオ トラックとバンドルする (オプション 3: 2 つ以上のビデオ ストリームにバンドルされたオーディオ) ことを強くお勧めします。

## <a name="7-service-failover"></a>7.サービスのフェールオーバー
ライブ ストリーミングの性質上、サービスの可用性を確保するためにはフェールオーバーを適切にサポートすることが重要です。 Media Services は、ネットワーク エラー、サーバー エラー、ストレージの問題など、さまざまな種類のエラーに対応するように設計されています。 ライブ エンコーダー側での適切なフェールオーバー ロジックを併用することにより、顧客は、クラウドを利用した信頼性の高いライブ ストリーミング サービスを実現できます。

このセクションでは、サービスのフェールオーバーのシナリオについて説明します。 このケースでは、フェールオーバーがサービス内で発生し、ネットワーク エラーとして出現します。 サービスのフェールオーバーに対応するエンコーダーの実装についての推奨事項を次に示します。

1. TCP 接続の確立に 10 秒のタイムアウトを使用します。 接続を確立するまでに 10 秒を超えた場合は操作を中止し、再試行します。 
1. HTTP 要求のメッセージ チャンクの送信に、短いタイムアウトを使用します。 ターゲット MP4 フラグメントの継続時間が N 秒の場合、N ～ 2N 秒の間の送信タイムアウトを使用します。たとえば、MP4 フラグメントの継続時間が 6 秒の場合は、6 - 12 秒のタイムアウトを使用します。 タイムアウトが発生したら、接続をリセットし、新しい接続を開いて、新しい接続でストリーム インジェストを再開します。 
1. サービスに対して正常にすべて送信された最後の 2 つのフラグメントが含まれるローリング バッファーを各トラックで維持します。  ストリームの HTTP POST 要求がストリームの終了前に終了またはタイムアウトした場合、新しい接続を開き、別の HTTP POST 要求を開始して、ストリーム ヘッダーを再送信し、各トラックの最後の 2 つのフラグメントを再送信することによって、メディア タイムラインに不連続性を発生させずにストリームを再開します。 これにより、データが失われる確率が減少します。
1. エンコーダーで、接続を確立する際や TCP エラーが発生した後にストリーミングを再開する際の再試行回数を制限しないことをお勧めします。
1. TCP エラー後: 
  
    a. 現在の接続を終了し、新しい HTTP POST 要求用に新しい接続を作成しなければなりません。

    b. 新しい HTTP POST URL は、最初の POST URL と同じでなければなりません。
  
    c. 新しい HTTP POST URL には、最初の POST と同じストリーム ヘッダー (**ftyp**、**Live Server Manifest Box**、**moov** ボックス) が含まれていなければなりません。
  
    d. 各トラックに送信された最後の 2 つのフラグメントを再送信し、メディア タイムラインに不連続性を発生させずにストリーミングを再開しなければなりません。 HTTP POST 要求間であっても、MP4 フラグメントのタイムスタンプは継続的に増加しなければなりません。
1. エンコーダーは、MP4 フラグメントの継続時間と同等の速度でデータが送信されていない場合、HTTP POST 要求を終了する必要があります。  データを送信しない HTTP POST 要求により、サービス更新時に Media Services がエンコーダーから即時に切断されるのを防止できます。 この理由から、スパース (ad 信号) トラックの HTTP POST は、スパース フラグメントが送信されるとすぐに終了するように短期間に設定する必要があります。

## <a name="8-encoder-failover"></a>8.エンコーダーのフェールオーバー
エンコーダーのフェールオーバーは、エンド ツー エンドのライブ ストリーミング配信用に対応する必要がある、2 つ目のフェールオーバー シナリオのタイプです。 このシナリオでは、エンコーダー側でエラー状態が発生しました。 

![エンコーダーのフェールオーバー][image5]

エンコーダーのフェールオーバーが発生した際にライブ インジェストのエンドポイントで予測される内容は次のとおりです。

1. 図に示すように (破線が付いている 3000 k のビデオ ストリーム)、ストリーミングを継続するためにエンコーダーの新しいインスタンスを作成する必要があります。
1. 新しいエンコーダーは、失敗したインスタンスと同じ URL を HTTP POST 要求に使用しなければなりません。
1. 新しいエンコーダーの POST 要求には、失敗したインスタンスと同じ Fragmented MP4 ヘッダー ボックスを含めなければなりません。
1. 新しいエンコーダーは、同じライブ プレゼンテーションに対して実行中の他のすべてのエンコーダーと正しく同期し、整列されたフラグメント境界と同期されたオーディオ サンプルとビデオ サンプルを生成しなければなりません。
1. 新しいストリームは、前のストリームと同等の意味を持ち、ヘッダーとフラグメント レベルで交換可能でなければなりません。
1. 新しいエンコーダーはデータの損失を最小限に抑える必要があります。 メディア フラグメントの `fragment_absolute_time` と `fragment_index` は、エンコーダーが最後に停止した位置から増加する必要があります。 `fragment_absolute_time` と `fragment_index` は継続的に増加する必要がありますが、必要に応じて不連続性も許容されます。 Media Services は既に受信して処理されたフラグメントを無視するので、メディア タイムラインで不連続性を発生させるよりも、フラグメントの再送信でエラーを発生させる方が有効です。 

## <a name="9-encoder-redundancy"></a>9.エンコーダーの冗長性
さらに高い可用性と高品質が要求される重要なライブ イベントでは、アクティブ/アクティブの冗長エンコーダーを使用して、データを失わないシームレスなフェールオーバーを実現することをお勧めします。

![エンコーダーの冗長性][image6]

図のように、各ストリームの 2 つのコピーをライブ サービスに同時にプッシュする 2 つのエンコーダー グループがあります。 Media Services はストリーム ID とフラグメントのタイムスタンプに基づいて重複するフラグメントを除外できるため、このセットアップがサポートされています。 その結果得られるライブ ストリームとアーカイブは、2 つのソースの最適な収集結果である、すべてのストリームをまとめた 1 つのコピーになります。 たとえば、極端な例を仮定した場合、各ストリームで 1 つのエンコーダー (同じエンコーダーである必要はありません) がどの時点においても常に実行されている限り、サービスから得られるライブ ストリームは継続的であり、データの損失はありません。 

このシナリオの要件は、エンコーダーの 2 つ目のセットがエンコーダーの 1 つ目のセットと同時に実行している点を除いて、「エンコーダーのフェールオーバー」の要件とほとんど同じです。

## <a name="10-service-redundancy"></a>10.サービスの冗長性
冗長性の高いグローバル配信の場合、地域的な障害に対処するためにリージョン間バックアップが必要になる場合があります。 「エンコーダー冗長性」トポロジで拡張すると、顧客はエンコーダーの 2 つ目のセットに接続されている別のリージョンで冗長サービス デプロイメントを選択できます。 顧客は、Content Delivery Network プロバイダーで作業し、2 つのサービス デプロイメントの前に Global Traffic Manager をデプロイし、クライアント トラフィックをシームレスにルーティングすることもできます。 エンコーダーの要件は、「エンコーダーの冗長性」の場合と同じです。 唯一の例外は、エンコーダーの 2 つ目のセットで別のライブ インジェスト エンドポイントをポイントする必要があることです。 次の図に、このセットアップを示します。

![サービスの冗長性][image7]

## <a name="11-special-types-of-ingestion-formats"></a>11.特殊なタイプのインジェスト形式
このセクションでは、特定のシナリオに対応するように設計されている特殊なタイプのライブ インジェスト形式について説明します。

### <a name="sparse-track"></a>スパース トラック
リッチ クライアント エクスペリエンスのライブ ストリーミング プレゼンテーションを配信する際は、多くの場合、主要メディア データを時刻同期されたイベントまたはインバンド信号とともに送信することが重要になります。 動的なライブ広告挿入はその一例です。 この種類のイベント シグナルは、スパースの性質上、通常のオーディオ/ビデオ ストリーミングとは異なります。 つまり、シグナル化データは、通常は継続的に発生しないため、インターバルの予測が困難な場合があります。 スパース トラックの概念は、インバンドのシグナル化データを取り込み、ブロードキャストする目的で設計されました。

次に示す手順は、スパース トラックのインジェストに推奨される実装です。

1. オーディオ トラックとビデオ トラックのない、スパース トラックだけが含まれる独立した Fragmented MP4 ビットストリームを作成します。
1. [1] のセクション 6 で定義した **Live Server Manifest Box** で、*parentTrackName* パラメーターを使用して親トラックの名前を指定します。詳細については、[1] のセクション 4.2.1.2.1.2 をご覧ください。
1. **Live Server Manifest Box** では、**manifestOutput** を **true** に設定しなければなりません。
1. シグナル化イベントのスパースの性質上、次をお勧めします。
   
    a. ライブ イベントの最初に、エンコーダーで初期ヘッダー ボックスをサービスに送信します。これにより、サービスでクライアント マニフェストにスパース トラックを登録できます。
   
    b. エンコーダーは、データが送信されていないときに HTTP POST 要求を終了する必要があります。 データを送信しない長時間実行している HTTP POST により、サービスの更新やサーバーの再起動が発生した場合にも、Media Services がエンコーダーから即時に切断されるのを防止できます。 このような場合には、メディア サーバーがソケットでの受信操作で一時的にブロックされます。
   
    c. シグナル化データが利用できない間は、エンコーダーは HTTP POST 要求を終了する必要があります。 POST 要求がアクティブな間は、エンコーダーは、データを送信する必要があります。

    d. スパース フラグメントを送信する場合、エンコーダーはコンテンツ長ヘッダー (使用可能な場合) を明示的に設定できます。

    e. 新しい接続でスパース フラグメントを送信する場合、エンコーダーは、新しいフラグメントが後に続くヘッダー ボックスから送信を開始する必要があります。 これは、スパース トラックがまだ確認されたことのない新しいサーバーへの新しいスパースの接続が確立されている間にフェールオーバーが発生した場合に対応するためです。

    f. スパース トラックのフラグメントは、同等またはそれ以上のタイムスタンプ値を持つ対応する親トラック フラグメントがクライアントに利用可能になると、クライアントが使用できるようになります。 たとえば、スパース フラグメントのタイムスタンプが t=1000 のとき、クライアントがビデオ (親トラック名が "video" であると想定) を視聴した後のフラグメント タイムスタンプは 1000 またはそれ以上であることが予想され、スパース フラグメント t=1000 をダウンロードできます。 実際の信号は、目的に応じてプレゼンテーションのタイムラインの別の位置でも使用できます。 この例では、t=1000 のスパース フラグメントに広告を挿入する目的で数秒後の位置に XML ペイロードを含めることも可能です。

    g. スパース トラック フラグメントのペイロードは、さまざまなシナリオに応じて異なる形式 (XML、テキスト、バイナリなど) にすることができます。

### <a name="redundant-audio-track"></a>冗長オーディオ トラック
一般的な HTTP アダプティブ ストリーミングのシナリオ (Smooth Streaming または DASH など) では、プレゼンテーション全体にオーディオ トラックが 1 つだけの場合がよくあります。 クライアントがエラー状態において選択できるように複数の品質レベルが用意されているビデオ トラックとは異なり、オーディオ トラックでは、オーディオ トラックを含むストリームのインジェストが破損している場合、単一障害点になる可能性があります。 

この問題を解決するために、Media Services では冗長オーディオ トラックのライブ インジェストをサポートしています。 これは、同じオーディオ トラックを異なるストリームで複数回送信可能にするためです。 サービスでクライアント マニフェストにオーディオ トラックを登録するのは 1 回だけですが、プライマリ オーディオ トラックに問題が発生した場合にオーディオ フラグメントを取り出せるよう、冗長オーディオ トラックをバックアップとして使用できます。 冗長オーディオ トラックをインジェストするためには、エンコーダーで次を行う必要があります。

1. 複数の Fragment MP4 ビットストリームで同じのオーディオ トラックを作成します。 冗長オーディオ トラックは、同じフラグメントのタイムスタンプと意味的に同等であり、ヘッダーとフラグメント レベルで交換可能でなければなりません。
1. Live Server Manifest ([1] のセクション 6) の「オーディオ」エントリがすべての冗長オーディオ トラックに対して同じであることを確認します。

冗長オーディオ トラックでは次の実装をお勧めします。

1. ストリームでそれぞれ固有のオーディオ トラックを単独で送信します。 また、これらのオーディオ トラックの各ストリームに冗長ストリームを送信します。2 つ目のストリームと最初のストリームとの違いは、HTTP POST URL ({protocol}://{server address}/{publishing point path}/Streams({identifier})) 内の識別子のみです。
1. 個別のストリームを使用して最も低い 2 つビデオ ビットレートを送信します。 これらのストリームにはそれぞれ固有のオーディオ トラックのコピーを含める必要があります。たとえば、複数の言語がサポートされている場合、これらのストリームに各言語のオーディオ トラックを含める必要があります。
1. 個別のサーバー (エンコーダー) のインスタンスを使用して、(1) と (2) の手順に従い冗長ストリームをエンコードし、送信します。 

## <a name="media-services-learning-paths"></a>Media Services のラーニング パス
[!INCLUDE [media-services-learning-paths-include](../../../includes/media-services-learning-paths-include.md)]

## <a name="provide-feedback"></a>フィードバックの提供
[!INCLUDE [media-services-user-voice-include](../../../includes/media-services-user-voice-include.md)]

[image1]: ./media/media-services-fmp4-live-ingest-overview/media-services-image1.png
[image2]: ./media/media-services-fmp4-live-ingest-overview/media-services-image2.png
[image3]: ./media/media-services-fmp4-live-ingest-overview/media-services-image3.png
[image4]: ./media/media-services-fmp4-live-ingest-overview/media-services-image4.png
[image5]: ./media/media-services-fmp4-live-ingest-overview/media-services-image5.png
[image6]: ./media/media-services-fmp4-live-ingest-overview/media-services-image6.png
[image7]: ./media/media-services-fmp4-live-ingest-overview/media-services-image7.png
