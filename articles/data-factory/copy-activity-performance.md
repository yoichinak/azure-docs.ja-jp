---
title: Azure Data Factory のコピー アクティビティのパフォーマンスとチューニングに関するガイド | Microsoft Docs
description: コピー アクティビティを使用する場合に、Azure Data Factory でのデータ移動のパフォーマンスに影響する主な要因について説明します。
services: data-factory
documentationcenter: ''
author: linda33wj
manager: craigg
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: conceptual
ms.date: 07/06/2018
ms.author: jingwang
ms.openlocfilehash: 958d1ea09ce4d85afc59af412e1050efc6290a1a
ms.sourcegitcommit: e0a678acb0dc928e5c5edde3ca04e6854eb05ea6
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 07/13/2018
ms.locfileid: "39002247"
---
# <a name="copy-activity-performance-and-tuning-guide"></a>コピー アクティビティのパフォーマンスとチューニングに関するガイド
> [!div class="op_single_selector" title1="Select the version of Data Factory service you are using:"]
> * [Version 1](v1/data-factory-copy-activity-performance.md)
> * [現在のバージョン](copy-activity-performance.md)


Azure Data Factory コピー アクティビティは、優れたセキュリティで保護された、信頼性とパフォーマンスに優れたデータ読み込みソリューションを提供します。 これにより、数十テラバイトのデータを、さまざまなクラウドおよびオンプレミスのデータ ストアの間で毎日コピーすることができます。 データ読み込みのパフォーマンスを劇的に高めることが、高度な分析ソリューションを構築してすべてのデータから深い洞察を得るという、"ビッグ データ" の中心的問題に集中するための鍵となります。

Azure によりエンタープライズ クラスのデータ ストレージおよびデータ ウェアハウスのソリューション セットが提供されます。また、コピー アクティビティにより、構成とセットアップが簡単な、大幅に最適化されたデータ読み込み環境がもたらされます。 1 つのコピー アクティビティで次のことを実現できます。

* **Azure SQL Data Warehouse** へのデータの読み込み (**1.2 GBps**)。
* **Azure Blob Storage** へのデータの読み込み (**1.0 GBps**)
* **Azure Data Lake Store** へのデータの読み込み (**1.0 GBps**)

この記事では、次の内容について説明します。

* [パフォーマンス参照番号](#performance-reference) 
* [データ統合単位](#data-integration-units)、[並列コピー](#parallel-copy)、[ステージング コピー](#staged-copy)などのさまざまなシナリオにおけるコピーのスループットを高める機能
* [パフォーマンス チューニング ガイダンス](#performance-tuning-steps) 

> [!NOTE]
> コピー アクティビティ全般に慣れていない場合は、この記事を読む前に、[コピー アクティビティの概要](copy-activity-overview.md)に関するページを参照してください。
>

## <a name="performance-reference"></a>パフォーマンス リファレンス

参考として、社内テストに基づいて、**1 回のコピー アクティビティの実行**での特定のソースとシンクのペアにおけるコピー スループット (**Mbps 単位**) を次の表に示します。 比較のために、[データ統合単位](#data-integration-units)または[セルフホステッド統合ランタイムのスケーラビリティ](concepts-integration-runtime.md#self-hosted-integration-runtime) (複数のノード) の異なる設定によって、コピーのパフォーマンスがどのように変化するかも示しています。

![パフォーマンス マトリックス](./media/copy-activity-performance/CopyPerfRef.png)

> [!IMPORTANT]
> コピー アクティビティが Azure Integration Runtime で実行される場合、許可される最小のデータ統合単位 (旧称: データ移動単位) は 2 です。 指定しない場合に使用される既定のデータ統合単位については、「[データ統合単位](#data-integration-units)」をご覧ください。

注意する点:

* スループットの計算には、[ソースから読み取られたデータ サイズ]/[コピー アクティビティの実行時間] という数式を使用します。
* 表のパフォーマンスの参考数値は、1 回のコピー アクティビティ実行で [TPC-H](http://www.tpc.org/tpch/) データセットを使用して測定されました。
* Azure データ ストアでは、ソースとシンクは同じ Azure リージョンにあります。
* オンプレミスとクラウドのデータ ストア間のハイブリッド コピーの場合、各セルフホステッド統合ランタイム ノードは、以下の仕様でデータストアとは別のマシンで実行されました。 1 つのアクティビティの実行中、コピー操作で使用されたのは、テスト コンピューターの CPU、メモリ、またはネットワーク帯域幅のごく一部だけでした。
    <table>
    <tr>
        <td>CPU</td>
        <td>32 コア 2.20 GHz Intel Xeon E5-2660 v2</td>
    </tr>
    <tr>
        <td>メモリ</td>
        <td>128 GB</td>
    </tr>
    <tr>
        <td>ネットワーク</td>
        <td>インターネット インターフェイス: 10 Gbps。イントラネット インターフェイス: 40 Gbps</td>
    </tr>
    </table>


> [!TIP]
> 既定の最大許容データ統合単位 (DIU) は、クラウド間のコピー アクティビティの実行では 32 ですが、これよりも大きい DIU を使用すると、より高いスループットを得ることができます。 たとえば、100 DIU にすると、Azure BLOB から Azure Data Lake Store に **1.0 Gbps** でデータをコピーすることができます。 この機能の詳細とサポートされるシナリオについては、「[データ統合単位](#data-integration-units)」セクションをご覧ください。 DIU の追加依頼は、[Azure サポート](https://azure.microsoft.com/support/)に連絡してください。

## <a name="data-integration-units"></a>データ統合単位

**データ統合単位 (DIU)** (旧称: クラウド データ移動単位 (DMU)) は、Data Factory の 1 つの単位の能力 (CPU、メモリ、ネットワーク リソース割り当ての組み合わせ) を表す尺度です。 **DIU は [Azure 統合ランタイム](concepts-integration-runtime.md#azure-integration-runtime)** にのみ適用され、[セルフホステッド統合ランタイム](concepts-integration-runtime.md#self-hosted-integration-runtime)には適用されません。

**コピー アクティビティの実行を強化する最小データ統合単位は 2 です。** 指定しない場合、次の表に、さまざまなコピー シナリオで使用される既定の DIU を示します。

| コピー シナリオ | サービスによって決定される既定の DIU |
|:--- |:--- |
| ファイル ベースのストア間でのデータのコピー | ファイルの数とサイズに応じて 4 〜 32。 |
| 他のすべてのコピー シナリオ | 4 |

この既定の動作をオーバーライドするには、**dataIntegrationUnits** プロパティに次のように値を指定します。 **dataIntegrationUnits** プロパティの**許容値**は**最大 256** です。 コピー操作が実行時に使用する **DIU の実際の数**は、データ パターンに応じて、構成されている値以下になります。 特定のコピー ソースおよびシンクに、より多くの単位を構成した場合に得られるパフォーマンス向上レベルの情報については、「 [パフォーマンス リファレンス](#performance-reference)」を参照してください。

アクティビティの実行の監視中に、コピー アクティビティの出力で、各コピー実行に実際に使用されたデータ統合単位を確認できます。 詳細については、[コピー アクティビティの監視](copy-activity-overview.md#monitoring)を参照してください。

> [!NOTE]
> スループットをより高めるためにさらに DIU が必要な場合は、[Azure サポート](https://azure.microsoft.com/support/)にお問い合わせください。 現在、8 以上を設定できるのは、**複数のファイルを、Blob Storage/Data Lake Store/Amazon S3/クラウド FTP/クラウド SFTP から他の任意のクラウド データ ストアにコピーする**場合のみです。
>

**例:**

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "dataIntegrationUnits": 32
        }
    }
]
```

### <a name="data-integration-units-billing-impact"></a>データ統合単位の課金への影響

**重要** なのは、コピー操作の合計時間に基づいて料金が請求されることです。 データ移動に対して課金される合計期間は、DIU 全体の期間の合計です。 これまで 1 回のコピー ジョブに 2 クラウド単位で 1 時間かかっていたのが、8 クラウド単位で 15 分かかるようになった場合、全体の請求金額はほぼ同じままです。

## <a name="parallel-copy"></a>並列コピー

**parallelCopies** プロパティを使用して、コピー アクティビティで使用する並列処理を指定することができます。 このプロパティは、並行してソースからの読み取りまたはシンク データ ストアへの書き込みを行うことができる、コピー アクティビティ内のスレッドの最大数と考えることができます。

コピー アクティビティの実行ごとに、Data Factory は、ソース データ ストアからターゲット データ ストアへのデータ コピーで使用する並列コピーの数を決定します。 使用される並列コピーの既定数は、使用しているソースとシンクの種類によって異なります。

| コピー シナリオ | サービスによって決定される並列コピーの既定数 |
| --- | --- |
| ファイル ベースのストア間でのデータのコピー |ファイルのサイズと、2 つのクラウド データ ストア間でのデータのコピーで使用されるデータ統合単位 (DMU) の数またはセルフホステッド統合ランタイム マシンの物理構成によって異なります。 |
| 任意のソース データ ストアから Azure Table Storage へのデータのコピー |4 |
| 他のすべてのコピー シナリオ |1 |

[!TIP]
> ファイル ベースのストア間でデータをコピーするとき、通常は既定の動作 (自動的に決定される) によって最高のスループットが得られます。 

データ ストアをホストしているコンピューターの負荷を制御したり、コピーのパフォーマンスをチューニングしたりするには、**parallelCopies** プロパティの値を指定して、既定値をオーバーライドできます。 値は 1 以上の整数でなければなりません。 実行時にコピー アクティビティは、設定された値以下でパフォーマンスが最大になる値を使用します。

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 32
        }
    }
]
```

注意する点:

* ファイル ベースのストア間でデータをコピーする場合は、**parallelCopies** によってファイル レベルでの並列処理が決まります。 単一ファイル内でのチャンク化は裏で自動的かつ透過的に行われます。また、指定されたソース データ ストアの種類に最適なチャンク サイズを使用し、parallelCopies とは独立に並行してデータを読み込むよう設計されています。 実行時にコピー操作でデータ移動サービスに使用される並列コピーの実際の数は、存在するファイルの数以下となります。 コピー動作が **mergeFile** の場合、コピー アクティビティはファイル レベルでの並列処理を活用できません。
* **parallelCopies** プロパティの値を指定する場合、ソースおよびシンク データ ストアへの負荷の増加、およびハイブリッド コピーの場合など、コピー アクティビティがセルフホステッド統合ランタイムで強化されている場合のそれに対する負荷の増加を考慮してください。 これは、特に複数のアクティビティがある場合や、同じデータ ストアに対して実行される同じアクティビティの同時実行がある場合によくあります。 データ ストアまたはセルフホステッド統合ランタイムの負荷の上限に達したことがわかった場合は、**parallelCopies** の値を減らし、負荷を軽減してください。
* ファイル ベース以外のストアからファイル ベースのストアにデータをコピーする場合、データ移動サービスは **parallelCopies** プロパティを無視します。 並列処理が指定されても、この場合は適用されません。
* **parallelCopies** は **dataIntegrationUnits** と無関係です。 前者はすべてのデータ統合単位全体でカウントされます。

## <a name="staged-copy"></a>ステージング コピー

ソース データ ストアからシンク データ ストアにデータをコピーする場合、中間のステージング ストアとして Blob Storage を使用できます。 ステージングは、特に次のような場合に役立ちます。

- **PolyBase を使ってさまざまなデータ ストアから SQL Data Warehouse にデータを取り込む**。 SQL Data Warehouse は、大量のデータを読み込むための高スループットのメカニズムとして PolyBase を使用します。 ただし、ソース データが Blob Storage または Azure Data Lake Store にあることと追加の条件を満たすことが必要です。 Blob Storage または Azure Data Lake Store 以外のデータ ストアからデータを読み込む際は、中間ステージング Blob Storage 経由のデータ コピーを有効にすることができます。 その場合、Data Factory は、PolyBase の要件を満たすために必要なデータ変換を実行します。 その後、PolyBase を使用して、効率的にデータを SQL Data Warehouse に読み込みます。 詳細については、「[PolyBase を使用して Azure SQL Data Warehouse にデータを読み込む](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse)」を参照してください。
- **ネットワーク接続が遅い場合、ハイブリッド データ移動 (オンプレミス データ ストアからクラウド データ ストアへのコピー) の実行に少し時間がかかる場合がある**。 パフォーマンスを向上させるため、ステージング コピーを使用してオンプレミスでデータを圧縮できるため、クラウド内のステージング データ ストアにデータを移動する時間が短縮され、移動先のデータ ストアに読み込む前にステージング ストア内のデータを展開できます。
- **企業の IT ポリシーが理由で、ファイアウォールでポート 80 とポート 443 以外のポートを開きたくない**。 たとえば、オンプレミス データ ストアから Azure SQL Database シンクまたは SQL Data Warehouse シンクにデータをコピーする場合、Windows ファイアウォールと会社のファイアウォールの両方で、ポート 1433 の送信 TCP 通信を有効にする必要があります。 このシナリオでは、ステージング コピーは、セルフホステッド統合ランタイムを利用して、まずポート 443 で HTTP または HTTPS 経由で Blob Storage ステージング インスタンスにデータをコピーしてから、Blob Storage ステージングから SQL Database または SQL Data Warehouse にデータを読み込みます。 このフローでは、ポート 1433 を有効にする必要はありません。

### <a name="how-staged-copy-works"></a>ステージング コピーのしくみ

ステージング機能を有効にすると、最初にデータがソース データ ストアからステージング Blob Storage (独自に用意) にコピーされます。 次に、データは、ステージング データ ストアからシンク データ ストアにコピーされます。 Data Factory では、2 段階のフローが自動的に管理されます。 また、データ移動の完了後、ステージング ストレージから一時データをクリーンアップします。

![ステージング コピー](media/copy-activity-performance/staged-copy.png)

ステージング ストアを使用したデータ移動を有効にすると、ソース データ ストアから中間またはステージング データ ストアにデータを移動する前にデータを圧縮し、中間またはステージング データ ストアからシンク データ ストアにデータを移動する前にそのデータの圧縮を解除するかどうかを指定できます。

現時点では、ステージング ストアを使用して 2 つのオンプレミス データ ストア間でデータをコピーすることはできません。

### <a name="configuration"></a>構成

コピー アクティビティの **enableStaging** 設定を構成して、目的のデータ ストアに読み込む前にデータを Blob Storage にステージングするかどうかを指定します。 **enableStaging** を `TRUE` に設定した場合は、次の表に記載されている追加のプロパティを指定する必要があります。 ステージング用に Azure Storage または Storage Shared Access Signature のリンクされたサービスがない場合は、作成する必要もあります。

| プロパティ | 説明 | 既定値 | 必須 |
| --- | --- | --- | --- |
| **enableStaging** |中間ステージング ストアを経由してデータをコピーするかどうかを指定します。 |False |いいえ |
| **linkedServiceName** |[AzureStorage ](connector-azure-blob-storage.md#linked-service-properties) のリンクされたサービスの名前を指定します。これは、中間ステージング ストアとして使用する Storage のインスタンスを表します。 <br/><br/> PolyBase を使用してデータを SQL Data Warehouse に読み込むために、Shared Access Signature を持つ Storage を使用することはできません。 それ以外のすべてのシナリオでは使用できます。 |該当なし |はい ( **enableStaging** が TRUE に設定されている場合) |
| **path** |ステージング データを格納する Blob Storage のパスを指定します。 パスを指定しないと、一時データを格納するコンテナーがサービスによって作成されます。 <br/><br/> パスを指定するのは、Shared Access Signature を持つ Storage を使用する場合、または一時データを特定の場所に保存する必要がある場合のみです。 |該当なし |いいえ |
| **enableCompression** |データをコピーする前に圧縮するかどうかを指定します。 この設定により、転送するデータの量が減ります。 |False |いいえ |

上の表に記載されているプロパティを持つコピー アクティビティの定義の例を次に示します。

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "SqlSource",
            },
            "sink": {
                "type": "SqlSink"
            },
            "enableStaging": true,
            "stagingSettings": {
                "linkedServiceName": {
                    "referenceName": "MyStagingBlob",
                    "type": "LinkedServiceReference"
                },
                "path": "stagingcontainer/path",
                "enableCompression": true
            }
        }
    }
]
```

### <a name="staged-copy-billing-impact"></a>ステージング コピーの課金への影響

コピーの期間とコピーの種類という 2 つのステップに基づいて課金されます。

* クラウド コピー (クラウド データ ストアから別のクラウド データ ストアへのデータのコピー、どちらのステージも Azure 統合ランタイムで強化されている) でステージングを使用する場合、料金は、"ステップ 1 とステップ 2 のコピー時間の合計" x "クラウド コピーの単価" で計算されます。
* ハイブリッド コピー (オンプレミス データ ストアからクラウド データ ストアへのデータのコピー、1 つのステージがセルフホステッド統合ランタイムで強化されている) でステージングを使用する場合、料金は、"ハイブリッド コピーの時間" x "ハイブリッド コピーの単価" + "クラウド コピーの時間" x "クラウド コピーの単価" で計算されます。

## <a name="performance-tuning-steps"></a>パフォーマンス チューニングの手順

Data Factory サービスとコピー アクティビティのパフォーマンスをチューニングするには、次の手順を実行することをお勧めします。

1. **ベースラインを確立する**。 開発フェーズでは、代表的なデータ サンプルに対してコピー アクティビティを使用して、パイプラインをテストします。 [コピー アクティビティの監視](copy-activity-overview.md#monitoring)の後に、実行の詳細とパフォーマンス特性を収集します。

2. **パフォーマンスを診断して最適化する**。 観測したパフォーマンスが予測どおりでない場合は、パフォーマンスのボトルネックを特定する必要があります。 次に、パフォーマンスを最適化して、ボトルネックの影響を除去するか軽減します。 この記事では、パフォーマンスの診断に関する詳細な説明は省略しますが、いくつかの一般的な考慮事項を次に示します。

   * パフォーマンス機能:
     * [並列コピー](#parallel-copy)
     * [データ統合単位](#data-integration-units)
     * [ステージング コピー](#staged-copy)
     * [セルフホステッド統合ランタイムのスケーラビリティ](concepts-integration-runtime.md#self-hosted-integration-runtime)
   * [セルフホステッド統合ランタイム](#considerations-for-self-hosted-integration-runtime)
   * [ソース](#considerations-for-the-source)
   * [シンク](#considerations-for-the-sink)
   * [シリアル化と逆シリアル化](#considerations-for-serialization-and-deserialization)
   * [圧縮](#considerations-for-compression)
   * [列マッピング](#considerations-for-column-mapping)
   * [その他の考慮事項](#other-considerations)

3. **構成をデータ セット全体に拡張する**。 実行結果とパフォーマンスに問題がなければ、データ セット全体を網羅するように定義とパイプラインを拡張することができます。

## <a name="considerations-for-self-hosted-integration-runtime"></a>セルフホステッド統合ランタイムに関する考慮事項

セルフホステッド統合ランタイムでコピー アクティビティが実行される場合は、次の点に注意してください。

**セットアップ**: 統合ランタイムをホストする専用のマシンを使用することをお勧めします。 [セルフホステッド統合ランタイムを使用する場合の考慮事項](concepts-integration-runtime.md)に関するページを参照してください。

**スケールアウト**: 1 つまたは複数のノードを持つ 1 つの論理セルフホステッド統合ランタイムは、同時実行される複数のコピー アクティビティに対応できます。 ハイブリッド データ移動で大量のコピー アクティビティを同時実行するか大量のデータをコピーする高いニーズがある場合は、コピー能力を高めるためにより多くのリソースをプロビジョニングできるように、[セルフホステッド統合ランタイムをスケール アウトする](create-self-hosted-integration-runtime.md#high-availability-and-scalability)ことを検討してください。

## <a name="considerations-for-the-source"></a>ソースに関する考慮事項

### <a name="general"></a>全般

基になるデータ ストアが、そこで実行されるその他のワークロードで手一杯になっていないことを確認します。

Microsoft のデータ ストアの場合は、データ ストアに特化した[監視とチューニングに関するトピック](#performance-reference)を参照してください。このトピックには、データ ストアのパフォーマンス特性に関する説明と、応答時間を短縮しスループットを最大限に高める方法が記載されています。

* **Blob Storage から SQL Data Warehouse に**データをコピーする場合は、 **PolyBase** を使用してパフォーマンスを向上させることを検討してください。 詳細については、「 [PolyBase を使用して Azure SQL Data Warehouse にデータを読み込む](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) 」を参照してください。
* **HDFS から Azure Blob/Azure Data Lake Store に**データをコピーする場合は、**DistCp** を使用してパフォーマンスを向上させることを検討してください。 詳細については、「[Use DistCp to copy data from HDFS](connector-hdfs.md#use-distcp-to-copy-data-from-hdfs)」(DistCpを使用して HDFS からデータをコピーする) を参照してください。
* **Redshift から Azure SQL Data Warehouse/Azure BLob/Azure Data Lake Store** にデータをコピーする場合は、**UNLOAD** を使用してパフォーマンスを向上させることを検討してください。 詳細については、「[Use UNLOAD to copy data from Amazon Redshift](connector-amazon-redshift.md#use-unload-to-copy-data-from-amazon-redshift)」(UNLOAD を使用して Amazon Redshift からデータをコピーする) を参照してください。

### <a name="file-based-data-stores"></a>ファイル ベースのデータ ストア

* **ファイル サイズとファイル数の平均**: コピー アクティビティはデータを 1 ファイルずつ転送します。 移動するデータ量は同じでも、データが少数の大きなファイルでなく、多数の小さなファイルで構成されている場合、ファイルごとにブートストラップ フェーズが存在するため、全体的なスループットは低下します。 したがって、可能であれば、小さなファイルをまとめて大きなファイルとすることで、スループットを高めてください。
* **ファイルの形式と圧縮**: パフォーマンスを向上させるその他の方法については、「[シリアル化と逆シリアル化に関する考慮事項](#considerations-for-serialization-and-deserialization)」と「[圧縮に関する考慮事項](#considerations-for-compression)」を参照してください。

### <a name="relational-data-stores"></a>リレーショナル データ ストア

* **データ パターン**: テーブル スキーマは、コピーのスループットに影響を与えます。 同じ量のデータをコピーする場合は、行のサイズが小さいよりも大きい方がパフォーマンスは高くなります。 これは、データベースは、データのバッチが少ないほど、また含まれている行が少ないほど、そのデータを効率的に取得できるためです。
* **クエリまたはストアド プロシージャ**: データをより効率的にフェッチできるように、コピー アクティビティ ソースで指定するクエリまたはストアド プロシージャのロジックを最適化します。

## <a name="considerations-for-the-sink"></a>シンクに関する考慮事項

### <a name="general"></a>全般

基になるデータ ストアが、そこで実行されるその他のワークロードで手一杯になっていないことを確認します。

Microsoft のデータ ストアについては、データ ストアに特化した [監視とチューニングに関するトピック](#performance-reference) を参照してください。 これらのトピックでは、データ ストアのパフォーマンス特性に関する説明と、応答時間を短縮しスループットを最大限に高める方法が記載されています。

* **Blob Storage から SQL Data Warehouse に**データをコピーする場合は、 **PolyBase** を使用してパフォーマンスを向上させることを検討してください。 詳細については、「 [PolyBase を使用して Azure SQL Data Warehouse にデータを読み込む](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) 」を参照してください。
* **HDFS から Azure Blob/Azure Data Lake Store に**データをコピーする場合は、**DistCp** を使用してパフォーマンスを向上させることを検討してください。 詳細については、「[Use DistCp to copy data from HDFS](connector-hdfs.md#use-distcp-to-copy-data-from-hdfs)」(DistCpを使用して HDFS からデータをコピーする) を参照してください。
* **Redshift から Azure SQL Data Warehouse/Azure BLob/Azure Data Lake Store** にデータをコピーする場合は、**UNLOAD** を使用してパフォーマンスを向上させることを検討してください。 詳細については、「[Use UNLOAD to copy data from Amazon Redshift](connector-amazon-redshift.md#use-unload-to-copy-data-from-amazon-redshift)」(UNLOAD を使用して Amazon Redshift からデータをコピーする) を参照してください。

### <a name="file-based-data-stores"></a>ファイル ベースのデータ ストア

* **コピー動作**: 別のファイル ベースのデータ ストアからデータをコピーする場合、コピー アクティビティには **copyBehavior** プロパティを使用したオプションが 3 つあります。 それらは、階層の維持、階層の平坦化、およびファイルのマージです。 階層の維持または階層の平坦化では、パフォーマンス オーバーヘッドはほとんどありませんが、ファイルのマージではパフォーマンス オーバーヘッドが増加します。
* **ファイルの形式と圧縮**: パフォーマンスを向上させるその他の方法については、「[シリアル化と逆シリアル化に関する考慮事項](#considerations-for-serialization-and-deserialization)」と「[圧縮に関する考慮事項](#considerations-for-compression)」を参照してください。

### <a name="relational-data-stores"></a>リレーショナル データ ストア

* **コピー動作**: コピー アクティビティは、**sqlSink** 用に設定されたプロパティに応じて、さまざまな方法でデータをターゲット データベースに書き込みます。
  * 既定では、データ移動サービスは、一括コピー API を使用して、データを追加モードで挿入します。これにより、最高のパフォーマンスが得られます。
  * シンク内でストアド プロシージャを構成すると、データベースは一括読み込みは行わず、一度に 1 行ずつデータを適用します。 パフォーマンスは大幅に低下します。 データ セットが大きい場合、代わりに **preCopyScript** プロパティを使用すること (適用できる場合) を検討してください。
  * 各コピー アクティビティの実行で **preCopyScript** プロパティを構成すると、サービスによってスクリプトがトリガーされるので、一括コピー API を使用してデータを挿入します。 たとえば、テーブル全体を最新のデータで上書きするには、ソースから新しいデータを一括で読み込む前にすべてのレコードを削除するためのスクリプトを指定することができます。
* **データのパターンとバッチ サイズ**:
  * テーブル スキーマは、コピーのスループットに影響を与えます。 同じ量のデータをコピーする場合、行のサイズが小さいよりも行のサイズが大きい方がパフォーマンスは高くなります。これは、データのバッチが少ない方が、データベースがデータを効率的にコミットできるためです。
  * コピー アクティビティは、一連のバッチでデータを挿入します。 バッチの行数は、 **writeBatchSize** プロパティを使用して設定できます。 データの行が小さい場合は、 **writeBatchSize** プロパティをより大きな値に設定することで、バッチ オーバーヘッドを減らし、スループットを向上させることができます。 データの行サイズが大きい場合は、 **writeBatchSize**を大きくするときに注意が必要です。 値を大きくすると、データベースに過剰な負荷がかかるため、コピーに失敗する可能性があります。

### <a name="nosql-stores"></a>NoSQL ストア

* **Table Storage**の場合:
  * **パーティション**: インターリーブされたパーティションにデータを書き込むと、パフォーマンスが大幅に低下します。 データが複数のパーティションに順次効率よく挿入されるように、パーティション キーでソース データを並べ替えるか、データが 1 つのパーティションに書き込まれるようにロジックを調整します。

## <a name="considerations-for-serialization-and-deserialization"></a>シリアル化と逆シリアル化に関する考慮事項

入力データ セットまたは出力データ セットがファイルであると、シリアル化および逆シリアル化が実行されることがあります。 コピー アクティビティでサポートされているファイル形式について詳しくは、「[サポートされているファイル形式と圧縮形式](supported-file-formats-and-compression-codecs.md)」をご覧ください。

**コピー動作**:

* ファイル ベースのデータ ストア間でファイルをコピーする:
  * 入力データ セットと出力データ セットが、両方とも同じファイル形式であるか、ファイル形式が設定されていない場合、データ移動サービスは、シリアル化または逆シリアル化を実行することなく、**バイナリ コピー**を実行します。 ソースとシンクのファイル形式の設定が互いに異なるシナリオと比較して、より高いスループットが示されます。
  * 入力データ セットと出力データ セットは両方ともテキスト形式で、エンコードの種類のみが異なる場合、データ移動サービスはエンコード変換のみを行います。 バイナリ コピーと比較した場合にパフォーマンス オーバーヘッドがいくらか発生するシリアル化と逆シリアル化は実行しません。
  * 入力データ セットと出力データ セットのファイル形式が異なるか、または構成 (区切り記号など) が異なる場合、データ移動サービスは、ソース データをストリームに逆シリアル化し、変換して、指定された出力形式にシリアル化します。 この操作では、他のシナリオと比較して、はるかに大きなパフォーマンス オーバーヘッドが発生します。
* ファイル ベースではないデータ ストアとの間で (たとえば、ファイル ベースのストアからリレーショナル ストアへの) コピーを行う場合、シリアル化または逆シリアル化の手順が必要になります。 この手順により、大幅なパフォーマンスのオーバーヘッドが発生します。

**ファイル形式**: ファイル形式の選択は、コピーのパフォーマンスに影響する場合があります。 たとえば、Avro は、データと共にメタデータを格納するコンパクトなバイナリ形式です。 Hadoop エコシステムでの処理やクエリ実行について、幅広くサポートされています。 ただし、Avro の場合は、シリアル化と逆シリアル化によってコピーのスループットが低下するので、テキスト形式と比較してコストがかかります。 処理フロー全体を考慮して、ファイル形式を選択してください。 まずは、データを格納する形式をソース データ ストアにするのか、外部システムから抽出するのか、ストレージや分析処理やクエリに最適な形式は何か、レポート ツールおよび視覚化ツール用にデータ マートにエクスポートするときの形式は何か、などを考慮する必要があります。 ときには、読み取りおよび書き込みパフォーマンスの点では準最適なファイル形式であっても、分析プロセス全体を考慮するとよい選択である場合があります。

## <a name="considerations-for-compression"></a>圧縮に関する考慮事項

入力データ セットまたは出力データ セットがファイルである場合は、ターゲットにデータを書き込むときに圧縮または圧縮解除を実行するようにコピー アクティビティを設定することができます。 圧縮を選択すると、入力/出力 (I/O) と CPU の間にトレードオフが生じます。 データを圧縮すると、コンピューティング リソースの面では余分なコストがかかります。 代わりに、ネットワーク I/O およびストレージは削減できます。 データによっては、コピーの全体的なスループットが大幅に向上する場合があります。

**コーデック**: 各圧縮コーデックには、長所があります。 たとえば、bzip2 はコピーのスループットが最も低いのですが、分割して処理できるため、最高の Hive クエリ パフォーマンスを発揮します。 Gzip は最もバランスの取れたオプションであり、最も頻繁に使用されます。 エンド ツー エンドのシナリオに最適なコーデックを選択してください。

**レベル:** 各圧縮コーデックに対して、最速圧縮と最適圧縮という 2 つのオプションのいずれかを選択できます。 最速圧縮オプションでは、可能な限り短時間でデータの圧縮を完了しますが、生成ファイルが最適に圧縮されない場合があります。 最適圧縮オプションでは、より多くの時間をデータ圧縮に費やしますが、データ量を最小限まで圧縮します。 両方のオプションを実際にテストして、どちらが全体的なパフォーマンスで優れているかを確認することができます。

**考慮事項**: オンプレミス ストアとクラウド間で大量のデータをコピーする場合は、圧縮を有効にした[ステージング コピー](#staged-copy)の使用を検討してください。 企業ネットワークと Azure サービスの帯域幅が制限要因となっていて、入力データ セットと出力データ セットの両方を圧縮されない形式にしたい場合は、中間ストレージを使用すると便利です。

## <a name="considerations-for-column-mapping"></a>列マッピングに関する考慮事項

コピー アクティビティの **columnMappings** プロパティを設定して、入力列のすべてまたはサブセットを出力列にマップすることができます。 データ移動サービスは、ソースからデータを読み取った後、データをシンクに書き込む前に、データに対して列マッピングを実行する必要があります。 この追加の処理により、コピーのスループットが低下します。

ソース データ ストアがクエリ可能な場合 (たとえば、SQL Database や SQL Server のようなリレーショナル ストアであるか、Table Storage や Azure Cosmos DB のような NoSQL ストアである場合) は、列マッピングを使用するのでなく、列フィルタリングと順序変更ロジックを **query** プロパティにプッシュすることを検討してください。 そうした場合、データ移動サービスがソース データ ストアからデータを読み取る際にプロジェクションが発生し、効率が大幅に向上します。

詳細については、[コピー アクティビティのスキーマ マッピング](copy-activity-schema-and-type-mapping.md)に関するページを参照してください。

## <a name="other-considerations"></a>その他の考慮事項

コピーするデータのサイズが大きい場合は、ビジネス ロジックを調整して、データを分割し、コピー アクティビティの実行頻度を増やすようにスケジュールして、各コピー アクティビティ実行のデータサイズを減らすことができます。

Data Factory で同じデータ ストアに同時に接続させる必要があるデータ セットの数とコピー アクティビティの数に注意してください。 同時コピー ジョブの数が多いと、データ ストアのスロットルが発生し、パフォーマンスの低下、コピー ジョブの内部的な再試行、場合によっては実行の失敗につながるおそれがあります。

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a>サンプル シナリオ: オンプレミス SQL Server から Blob Storage へのコピー

**シナリオ**: オンプレミスの SQL Server から Blob Storage に CSV 形式でデータをコピーするパイプラインが構築されています。 コピー ジョブを高速にするために、CSV ファイルは bzip2 形式で圧縮されます。

**テストと分析**: コピー アクティビティのスループットは 2 MBps 未満で、パフォーマンスのベンチマークをかなり下回っています。

**パフォーマンスの分析とチューニング**: パフォーマンスの問題を解決するために、データが処理、移動されるしくみを見ていきます。

1. **データの読み取り**: 統合ランタイムは、SQL Server への接続を開き、クエリを送信します。 SQL Server は、イントラネット経由で統合ランタイムにデータ ストリームを送信することで応答します。
2. **データのシリアル化と圧縮**: 統合ランタイムはデータ ストリームを CSV 形式にシリアル化し、データを bzip2 ストリームに圧縮します。
3. **データの書き込み**: 統合ランタイムは bzip2 ストリームをインターネット経由で Blob Storage にアップロードします。

ご覧のとおり、データは SQL Server、LAN、統合ランタイム、WAN、Blob Storage の順に、ストリーミングで順次処理および移動されています。 **全体的なパフォーマンスは、パイプラインを通じて最低のスループットが上限となっています**。

![Data flow](./media/copy-activity-performance/case-study-pic-1.png)

次に示す要因の 1 つ以上がパフォーマンスのボトルネックの原因である可能性があります。

* **ソース**: 負荷が大きいため、SQL Server 自体のスループットが低くなっています。
* **セルフホステッド統合ランタイム**：
  * **LAN**: 統合ランタイムは SQL Server コンピューターから離れた場所にあり、低帯域幅で接続されています。
  * **統合ランタイム**: 統合ランタイムは、以下の操作を実行して、負荷の上限に達しています。
    * **シリアル化**: CSV へのデータ ストリームのシリアル化で、スループットが低くなっています。
    * **圧縮**: 低速の圧縮コーデック (たとえば、Core i7 で 2.8 MBps の bzip2) を選択しました。
  * **WAN**: 企業ネットワークと Azure サービス間の帯域幅が小さい状態です (たとえば、T1 = 1,544 kbps、T2 = 6,312 kbps)。
* **シンク**: Blob Storage のスループットが低くなっています  (SLA により最低でも 60 MBps が保証されているため、このシナリオは現実的ではありません)。

この場合、bzip2 データ圧縮がパイプライン全体を遅くしている可能性があります。 gzip 圧縮コーデックに切り替えると、このボトルネックが緩和される場合があります。

## <a name="reference"></a>リファレンス

ここでは、サポートされているいくつかのデータ ストアについて、パフォーマンスの監視とチューニングに関するリファレンス情報を示します。

* Azure Storage (Blob Storage と Table Storage を含む): [Azure Storage のスケーラビリティのターゲット](../storage/common/storage-scalability-targets.md)に関する記事と [Azure Storage のパフォーマンスとスケーラビリティに対するチェック リスト](../storage/common/storage-performance-checklist.md)に関する記事
* Azure SQL Database: [パフォーマンスを監視](../sql-database/sql-database-single-database-monitor.md) し、データベース トランザクション ユニット (DTU) の割合を確認できます。
* Azure SQL Data Warehouse: 処理能力は Data Warehouse ユニット (DWU) で測定されます。「[Azure SQL Data Warehouse のコンピューティング能力の管理 (概要)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)」を参照してください。
* Azure Cosmos DB: [Azure Cosmos DB のパフォーマンス レベル](../cosmos-db/performance-levels.md)に関する記事
* オンプレミスの SQL Server: 「 [Monitor and tune for performance (パフォーマンスの監視とチューニング)](https://msdn.microsoft.com/library/ms189081.aspx)
* オンプレミスのファイル サーバー: 「 [Performance Tuning for File Servers (ファイル サーバーのパフォーマンス チューニング)](https://msdn.microsoft.com/library/dn567661.aspx)

## <a name="next-steps"></a>次の手順
コピー アクティビティの他の記事を参照してください。

- [コピー アクティビティの概要](copy-activity-overview.md)
- [コピー アクティビティのスキーマ マッピング](copy-activity-schema-and-type-mapping.md)
- [コピー アクティビティのフォールト トレランス](copy-activity-fault-tolerance.md)
